<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="Personal website of Dimitris Spathis, Senior AI Researcher at Nokia Bell Labs and Visiting Researcher at the University of Cambridge.">
  <meta name="author" content="Dimitris Spathis">
  <link rel="shortcut icon" href="https://www.cl.cam.ac.uk/favicon.ico" type="image/x-icon">
  <title>Dimitris Spathis — AI Researcher </title>

  <!-- CSS -->
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.1/css/bootstrap.min.css">
  <script src="https://kit.fontawesome.com/6294d10de4.js" crossorigin="anonymous"></script>
  <link rel="stylesheet" href="./css/main.css">

  <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
  <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
  <![endif]-->
</head>
<body>
  <div class="container">

    <div class="row" style="padding:20px">

      <!-- we hide the navbar in xs and sm breakpoints. Added a position relative to fix the navbar (also added a fixed inside the navbar below, see: https://jsfiddle.net/KyleMit/3RkM3)  -->
       <div class="hidden-xs hidden-sm col-sm-3 col-md-2" id="sidebar" role="navigation" style="margin-top:170px; position: relative;">
        <hr>
        <ul class="nav nav-pills nav-stacked" style="position: fixed;">
          <li><a href="#about">About</a></li>
          <li><a href="#publications">Publications</a></li>
          <li><a href="#service">Service</a></li>
          <li><a href="#talks">Talks</a></li>
          <li><a href="#press">Press</a></li>
          <li><a href="#teaching">Mentoring</a></li>
          <li><a href="#projects">Playground</a></li>
          <li><a href="#personal">Personal</a></li>

        </ul>
      </div>

      <div class="col-xs-12 col-sm-9 col-md-9">

        <div class="row">

          <div class="col-sm-3">

          <!-- we place the img -15px left to align with the divider  -->
          <img src="img/photo.jpg" class="pull-left" style="margin:20px
          20px 20px -15px; height:auto; width:130px; border-radius:50%"/>
          
          </div>

          <div class="col-sm-7">
            <h3><a name="about"></a>Hi 👋 I’m Dimitris Spathis</h3>
          <p class="lead">
            Senior AI Researcher <br>
            Nokia Bell Labs<br>
            <a href="mailto:ds806@cam.ac.uk" title="Academic email" class="icon">
              <i class="fa fa-envelope fa-lg" data-toggle="tooltip" data-placement="bottom" title="Email"></i>
            </a>
            &nbsp;
            <a href="https://scholar.google.com/citations?user=rzKYYlUAAAAJ" title="Google Scholar (publications list)" class="icon">
              <i class="fa fa-graduation-cap fa-lg" data-toggle="tooltip" data-placement="bottom" title="Google Scholar"></i>
            </a>
            &nbsp;
            <a href="https://github.com/sdimi" title="Github (code repository)" class="icon">
              <i class="fa fa-github fa-lg" data-toggle="tooltip" data-placement="bottom" title="Github"></i>
            </a>
            &nbsp;
            <a href="https://twitter.com/spdimitris" title="Twitter" class="icon">
              <i class="fa fa-twitter fa-lg" data-toggle="tooltip" data-placement="bottom" title="Twitter"></i>
            </a>
            &nbsp;
            <a href="https://medium.com/@dimitrisspathis" title="Medium (blog)" class="icon">
              <i class="fa fa-medium fa-lg" data-toggle="tooltip" data-placement="bottom" title="Medium (blog)"></i>
            </a>
            &nbsp;
            <a href="https://linkedin.com/in/dispathis" title="Linkedin (professional profile)" class="icon">
              <i class="fa fa-linkedin fa-lg" data-toggle="tooltip" data-placement="bottom" title="Linkedin"></i>
            </a>
           
          </p>
          </div>

          <!-- we hide the img in xs and sm breakpoints  -->
          
          <div class="col-sm-2 hidden-xs hidden-sm">
          <a href="https://www.bell-labs.com">
          <img  src="img/logo-bl.png" class="pull-right" style="margin:20px -33px 0px 0px;height:auto; width:144px; border-style: none"/>
          </a>
          
          </div>

          <div class="col-sm-2 hidden-xs hidden-sm">
          <a href="https://www.cst.cam.ac.uk/">
          <img  src="img/unilogo.png" class="pull-right" style="margin:-4px -18px 0px 0px;;height:auto; width:116px; border-style: none"/>
          </a>
          
          </div>
          


        </div>

        <div class="row">
          <hr>

          <p>
            I am a senior research scientist at <a href="https://www.bell-labs.com/">Nokia Bell Labs</a> and a visiting researcher at the <a href="https://www.cst.cam.ac.uk/">University of Cambridge</a>. My work enables AI to handle the messiness of the real world through human-centric, data-efficient, and robust machine learning. I am particularly interested in the following areas:

            <ul>
              <li><strong>AI for Sequential & Multimodal Data</strong>: I develop new AI models that make the most of high-frequency person-generated data through self-supervised learning [<a href="https://dl.acm.org/doi/10.1145/3450439.3451863">CHIL'21</a>], multimodal fusion [<a href="https://dl.acm.org/doi/10.1145/3616855.3635795">WSDM'24</a>], forecasting  [<a href="https://dl.acm.org/doi/abs/10.1145/3292500.3330730">KDD'19 oral</a>], and knowledge distillation [<a href=" https://dl.acm.org/doi/10.1145/3448112">UbiComp'21</a>].
              </li> 

              <li><strong>Accessible Health Sensing</strong>: I build AI systems that detect vital health information without specialized equipment, with applications to disease monitoring [<a href="https://datasets-benchmarks-proceedings.neurips.cc/paper_files/paper/2021/file/e2c0be24560d78c5e599c2a9c9d0bbd2-Paper-round2.pdf">NeurIPS'21</a>], cardio fitness [<a href=" https://www.nature.com/articles/s41746-022-00719-1">Nature Dig. Medicine'22</a>], sleep disorders [<a href=" https://www.nature.com/articles/s41598-022-11792-7">Sci. Reports'22</a>], and more.
              
              </li>

              <li><strong>Robust & Trustworthy AI</strong>: I develop reliable ML algorithms for high-stakes applications, focusing on out-of-distribution generalization [<a href=" https://arxiv.org/abs/2205.13398">ML4H'22,</a> <a href="https://aclanthology.org/W17-3005.pdf">ACLw'17</a>], addressing forgeting [<a href="https://openaccess.thecvf.com/content/WACV2024/papers/Tang_Kaizen_Practical_Self-Supervised_Continual_Learning_With_Continual_Fine-Tuning_WACV_2024_paper.pdf">WACV'24</a>], fairness [<a href="https://dispathis.com/SSLfairness">KDD'24</a>], and ethical considerations [<a href="https://doi.org/10.1093/jamia/ocab012">JAMIA'21</a>].
      
              </li>
            </ul>

          </p>
          <p>
              Previously, I completed a PhD in Computer Science at the <a href="https://www.cst.cam.ac.uk/">University of Cambridge</a> working with Prof. <a href="http://www.cl.cam.ac.uk/~cm542/">Cecilia Mascolo</a>. During my studies, I was fortunate to work in diverse industries and companies including <a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-cambridge/">Microsoft Research</a>, <a href="https://www.telefonica.com/en/web/innovation/core-innovation/research">Telefonica Research</a>, and <a href="https://www.ocadogroup.com/technology/technology-pioneers">Ocado</a>. I also helped start <a href="https://www.covid-19-sounds.org">COVID-19 Sounds</a>, one of the largest studies in audio AI for health.

          </p>

          <p>
          My research has been published in top venues in artificial intelligence, AI for health, and human-centered signal processing while recent projects have been featured in international media such as the BBC, CNN, Guardian, Washington Post, Forbes, and Financial Times (see more <a href="#press">below</a>). 
          </p>

          <p>
           <a href="cv.pdf"
              class="btn btn-default">CV <i class="fa fa fa-file-pdf-o fa-lg"></i></a>
          </p>
          


          <div class="alert alert-warning" id="news" role="alert">
          <p class="collapse" id="collapseExample" aria-expanded="false">

            <strong><font class="caps">october 2024</font></strong> • 

            We released <a href="2024-11-03 11:53:01">🦜 PaPaGei,</a> the first open foundation model for biosignals (PPG). You can read more <a href="https://www.linkedin.com/posts/dispathis_papagei-open-foundation-models-for-the-activity-7256952170028183552-3dcL?utm_source=share&utm_medium=member_desktop">here.</a> I was also interviewed by <a href="https://www.bloomberg.com/news/newsletters/2024-10-11/what-is-vo2-max">Bloomberg</a> on a newsletter about VO2max.

            
            <br><br>
            <strong><font class="caps">september 2024</font></strong> • 

            I was a panel speaker at <a href="https://cambridgetechweek.co.uk/people/dimitris-spathis/">Cambridge Tech Week.</a> You can watch the segment on <a href="https://youtu.be/vFZuKpvzMDE?t=8062">Youtube.</a>

            <br><br>
            <strong><font class="caps">august 2024</font></strong> • 

            <a href="https://arxiv.org/abs/2410.10048">StatioCL,</a> a new non-stationary self-supervised model for timeseries was accepted to CIKM 2024.  

            <br><br>
            <strong><font class="caps">july 2024</font></strong> • 

            Our work on how Large Language Models struggle with temporal data was published at <a href="https://academic.oup.com/jamia/advance-article/doi/10.1093/jamia/ocae090/7702405?utm_source=authortollfreelink&utm_campaign=jamia&utm_medium=email&guestAccessKey=fd83de2c-20ae-4508-a327-b9486e9d4202&login=false">JAMIA,</a> and was covered by <a href="https://techcrunch.com/2024/07/06/tokens-are-a-big-reason-todays-generative-ai-falls-short/">Techcrunch</a> and <a href="https://www.lgresearch.ai/blog/view?seq=428">LG AI Research.</a> You can read more on this <a href="https://www.linkedin.com/posts/dispathis_why-do-large-language-models-like-chatgpt-activity-7213851570944258051-M4qv?utm_source=share&utm_medium=member_desktop">post.</a>
          

             <br><br>

            <strong><font class="caps">june 2024</font></strong> • 

            Our work on how Self-Supervised Learning improves fairness was accepted at KDD 2024. We released the <a href="https://arxiv.org/abs/2406.02361">paper,</a> <a href="https://github.com/Nokia-Bell-Labs/SSLfairness">code,</a> and a <a href="https://dispathis.com/SSLfairness">project website.</a> I was also interviewed by <a href="https://www.runnersworld.com/training/a61402979/how-to-calculate-vo2-max/">Runner's World magazine</a> on a feature article about VO2max - you can read more <a href="https://www.linkedin.com/posts/dispathis_excited-to-share-that-our-research-on-estimating-activity-7212096895664488448-mkl2">here.</a> 
          

             <br><br>

            <strong><font class="caps">may 2024</font></strong> • 

            My MedAI talk from earlier this year is now available on <a href="https://www.youtube.com/watch?v=OsToQ0LcLsc">Youtube.</a> 
          

             <br><br>

            <strong><font class="caps">april 2024</font></strong> • 

            I was interviewed by the <a href="https://archive.ph/ZRPsa">New York Times</a> for an article on cardio fitness and wearables. Also launched a new Short Papers section at <a href="https://www.computer.org/digital-library/magazines/pc/cfp-research-brief/">IEEE Pervasive journal</a> - consider submitting your works! In addition, my <a href="https://patents.google.com/patent/US20240127057A1/en">first patent</a> from a few years ago became public; you can read more <a href="https://www.linkedin.com/posts/dispathis_my-very-first-patent-from-2022-is-finally-activity-7188448325501616128-9V3u">here.</a>
          

             <br><br>

            <strong><font class="caps">march 2024</font></strong> • 

            The collection of accepted papers at the <a href="https://hcrl-workshop.github.io/2024/">Human-Centric Representation Learning workshop</a> is available as an <a href="https://arxiv.org/abs/2403.10561">Arxiv index.</a>
          

             <br><br>

            <strong><font class="caps">february 2024</font></strong> • 

            Co-chaired the <a href="https://hcrl-workshop.github.io/2024/">Human-Centric Representation Learning workshop</a> at AAAI 2024 in Vancouver, with a great set of papers and keynotes -  you can read some highlights of the day at <a href="https://aihub.org/2024/03/18/aaai2024-workshops-round-up-3-human-centric-representation-learning-and-ai-to-accelerate-science-and-engineering/">AIhub.org.</a> I also gave an invited <a href="https://w3phiai2024.w3phi.com/keynote-speakers.html/">keynote</a> at the Health Intelligence workshop of the same conference (here are the <a href="files/AAAI24_Health_Intelligence_keynote_Spathis.pdf">slides</a> of the talk).
          

             <br><br>

            <strong><font class="caps">january 2024</font></strong> • 

            Gave an invited <a href="https://talks.cam.ac.uk/talk/index/210049/">talk</a> at Cambridge Biomedical Campus as part of the MedAI seminar series. 
          

             <br><br>

            <strong><font class="caps">december 2023</font></strong> • 

            I authored a <a href="https://www.bell-labs.com/institute/articles/the-future-of-personal-device-intelligence/">corporate blogpost</a> describing our team's recent research. I also joined the editorial board of the <a href="https://www.computer.org/csdl/magazine/pc/about/15004">IEEE Pervasive Computing</a> journal.  
          

             <br><br>

            <strong><font class="caps">november 2023</font></strong> • 

            Our review paper on Human-centered AI was published at <a href="https://royalsocietypublishing.org/doi/10.1098/rsos.230806">Royal Society Open Science.</a> I gave a talk at the ELLIS Unit hosted by Microsoft Research [<a href="https://www.ellis.eng.cam.ac.uk/microsoft-ai-pizza-talk-30-november-2023/">event,</a> <a href="files/MSR_AI_Pizza_Nov2023.pdf">slides]</a> while our fitness work was <a href="https://issuu.com/jesuscollege1496/docs/jesus_college_annual_report_2023v24/36">featured</a> at the 119th annual report of Jesus College.

             <br><br>

            <strong><font class="caps">october 2023</font></strong> • 

            Presented our preliminary <a href="https://arxiv.org/abs/2309.06236">work</a> on large language models for timeseries at the GenAI symposium of UbiComp 2023, where I also served as a <a href="https://www.ubicomp.org/ubicomp-iswc-2023/program/workshops-and-symposia/genai4pc-symposium/">panel member.</a> I also helped with organizing <a href="https://faircomp-workshop.github.io/2023/">FairComp</a> and <a href="https://wellcomp-workshop.github.io/2023/">WellComp.</a>

             <br><br>

            <strong><font class="caps">september 2023</font></strong> • 

            Presented our <a href="https://arxiv.org/abs/2307.12075">work</a> on machine learning fairness in mobile computing at MobileHCI 2023, where I also served as a <a href="https://mobilehci.acm.org/2023/program.php">session chair</a> in Industry Perspectives. I was honored to join the editorial board of <a href="https://www.nature.com/npjdigitalmed">Nature Digital Medicine.</a> I am also thrilled to announce the <a href="https://hcrl-workshop.github.io/2024/">Human-Centric Representation Learning workshop</a> at AAAI 2024.

             <br><br>

            <strong><font class="caps">august 2023</font></strong> • 

            Presented our <a href="https://arxiv.org/abs/2307.16847">work</a> on latent masking for multimodal learning at the ML4MHD workshop of ICML 2023 - video <a href="https://slideslive.com/39006577">here.</a> Also featured in an <a href="https://www.owkin.com/newsfeed/surfing-the-healthcare-wave-at-icml">article</a> by Owkin.

             <br><br>

            <strong><font class="caps">july 2023</font></strong> • 

            Our paper on domain adaptation for noisy label learning was accepted at <a href="https://static1.squarespace.com/static/59d5ac1780bd5ef9c396eda6/t/64d1a853a6742348f6a5f56c/1691461716532/ID136_Research+Paper_2023.pdf">Machine Learning for Healthcare</a> conference (MLHC 2023).

             <br><br>


            <strong><font class="caps">june 2023</font></strong> • 

            With the organizers of the Research Roundtables at ML4H 2022 we released a <a href="https://zenodo.org/record/7951122/files/ML4H_2022_Research_Roundtables.pdf?download=1">report</a> on <i>"Recent Advances, Applications and Open Challenges in Machine Learning for Health"</i>.

             <br><br>

            <strong><font class="caps">may 2023</font></strong> • 

            Our music preferences paper was featured in the german newspaper <a href="https://archive.ph/eABli">Der Tagesspiegel.</a> A <a href="https://www.jmir.org/2023/1/e44804">paper</a> <i>"Evaluating Listening Performance for COVID-19 Detection by Clinicians and Machine Learning: Comparative Study"</i> was published in JMIR, and a <a href="https://mobile-systems.cl.cam.ac.uk/papers/kdd23.pdf">paper</a> <i>"Conditional Neural ODE Processes for Individual Disease Progression Forecasting: A Case Study on COVID-19"</i> will appear in KDD 2023.

             <br><br>

            <strong><font class="caps">april 2023</font></strong> • 

            We are organizing <a href="https://faircomp-workshop.github.io/2023/">FairComp</a> and <a href="https://wellcomp-workshop.github.io/2023/">WellComp</a> workshops at <a href="https://www.ubicomp.org/ubicomp-iswc-2023/">UbiComp 2023</a> in Mexico - consider submitting your best works!

             <br><br>

            <strong><font class="caps">march 2023</font></strong> • 

            Gave an invited talk on human-centric AI for health signals at a <a href="https://www.cph.cam.ac.uk/events/using-mobiles-and-wearables-public-health">symposium</a> organized by Cambridge Public Health and the Precision Health Initiative. My talk is available on <a href="https://youtu.be/jjiMxbIi2IQ">Youtube.</a>

             <br><br>

            <strong><font class="caps">february 2023</font></strong> • 

            I was selected as a 'Rising Star in AI' by <a href="https://en.wikipedia.org/wiki/J%C3%BCrgen_Schmidhuber">Jürgen Schmidhuber's</a> AI initiative at KAUST and had the opportunity to talk at the honorary <a href="https://cemse.kaust.edu.sa/ai/aii-symp-2023">symposium.</a> Also, our fitness work was covered by the <a href="https://www.mirror.co.uk/news/health/put-your-fitness-test-latest-29176920/">Daily Mirror.</a>
             


        </p>
          <a role="button" class="collapsed" data-toggle="collapse" href="#collapseExample" aria-expanded="false" aria-controls="collapseExample">
          </a>
        
          </div>

      </div>

        <div class="row">
          <h2><a name="publications"></a>📖 Publications</h2>
          <hr>

          <h3>2024</h3>

          <!-- papagei -->
        <div class="media">
          <div class="media-left media-middle hidden-xs hidden-sm">
            <a href="img/papagei.png">
              <img class="media-object" src="img/papagei.png"  style="max-width:250px;" alt="npj">
            </a>
          </div>
          <div class="media-body">
            <h4 class="media-heading"><strong>🦜PaPaGei: Open Foundation Models for Optical Physiological Signals</strong></h4>
            <p>Arvind Pillai, <i>Dimitris Spathis</i>, Fahim Kawsar, Mohammad Malekzadeh<br>
            <em> NeurIPS Workshop on Time Series in the Age of Large Models <a href="https://neurips-time-series-workshop.github.io/"
>(TSALM @ NeurIPS'24),</a></em> Vancouver, Canada <br> (long paper under review)<br>
<font class="caps" color=#be1e2d><i class="fa fa-star fa-xs"></i> Oral presentation</font>
                <div class="btn-group-sm">
                  <a href="https://arxiv.org/abs/2410.20542"
                  class="btn btn-default"><i class="fa fa-link fa-lg"></i> DOI </a>
                  <a href="https://arxiv.org/pdf/2410.20542"
                  class="btn btn-default"><i class="fa fa-file-pdf-o fa-lg"></i> PDF</a>
                  <a href="https://github.com/nokia-bell-labs/papagei-foundation-model"
                class="btn btn-default"><i class="fa fa-github fa-lg"></i> Code</a>
                <a href="https://zenodo.org/records/13983110"
                class="btn btn-default"><i class="fa fa-brain fa-lg"></i> Models</a>
              
                </div>     
          </div>
        </div>

           <!--JAMIA &  GenAI @ UbiComp 2023 -->
         <div class="media">
          <div class="media-left media-middle hidden-xs hidden-sm">
            <a href="img/genAIPC23.png">
              <img class="media-object" src="img/genAIPC23.png"  style="max-width:250px;" alt="npj">
            </a>
          </div>
          <div class="media-body">
            <h4 class="media-heading"><strong>The first step is the hardest: Pitfalls of Representing and
              Tokenizing Temporal Data for Large Language Models</strong></h4>
            <p><i>Dimitris Spathis</i>, Fahim Kawsar <br>
              <em><a href="https://academic.oup.com/jamia/advance-article/doi/10.1093/jamia/ocae090/7702405?utm_source=authortollfreelink&utm_campaign=jamia&utm_medium=email&guestAccessKey=fd83de2c-20ae-4508-a327-b9486e9d4202&login=false"
                >Journal of the American Medical Informatics Association</a></em> <br>
 also presented in: <em>Generative AI for Pervasive Computing Symposium (GenAI4PC) at UbiComp 2023, Cancun, Mexico</em> <br>
                <div class="btn-group-sm">
                  <a href="https://academic.oup.com/jamia/advance-article/doi/10.1093/jamia/ocae090/7702405?utm_source=authortollfreelink&utm_campaign=jamia&utm_medium=email&guestAccessKey=fd83de2c-20ae-4508-a327-b9486e9d4202&login=false"
                  class="btn btn-default"><i class="fa fa-link fa-lg"></i> DOI </a>
                  <a href="https://api.repository.cam.ac.uk/server/api/core/bitstreams/ce594e4a-7a4c-41dd-a986-a705d8a6166c/content"
                  class="btn btn-default"><i class="fa fa-file-pdf-o fa-lg"></i> PDF</a>
                  
                </div>     
          </div>
        </div> 
        
        <!-- KDD & HCRL SSL 2024 -->
        <div class="media">
          <div class="media-left media-middle hidden-xs hidden-sm">
            <a href="img/fairSSL.png">
              <img class="media-object" src="img/fairSSL.png"  style="max-width:250px;" alt="npj">
            </a>
          </div>
          <div class="media-body">
            <h4 class="media-heading"><strong>Using Self-Supervised Learning Can Improve Model Fairness</strong></h4>
            <p>Sofia Yfantidou, <i>Dimitris Spathis</i>, Marios Constantinides, Athena Vakali, Daniele Quercia, Fahim Kawsar <br>
              <em>International Conference on Knowledge Discovery and Data Mining<a href="https://dispathis.com/SSLfairness"
                >
  (KDD'24)</a></em>, Barcelona, Spain <br>
                also presented in: <em> Human-centric Representation Learning workshop at AAAI 2024, Vancouver, Canada</em> <br>
                <div class="btn-group-sm">
                  <a href="https://arxiv.org/abs/2406.02361"
                  class="btn btn-default"><i class="fa fa-link fa-lg"></i> DOI </a>
                  <a href="https://arxiv.org/pdf/2406.02361"
                  class="btn btn-default"><i class="fa fa-file-pdf-o fa-lg"></i> PDF</a>
                  <a href="https://github.com/Nokia-Bell-Labs/SSLfairness"
                class="btn btn-default"><i class="fa fa-github fa-lg"></i> Code</a>
                <a href="https://www.youtube.com/watch?si=Hsf1EsUxxYMlok0j&v=wDn-g7GlfRw&feature=youtu.be"
                  class="btn btn-default"><i class="fa fa-video-camera fa-lg"></i> Video (2mins)</a>
                  <a href="https://dispathis.com/SSLfairness"
              class="btn btn-default"><i class="fa fa-newspaper-o fa-lg"></i> Project website</a>
                </div>     
          </div>
        </div>  

          <!-- WSDM 2024 + ICMLw 2023 -->
        <div class="media">
          <div class="media-left media-middle hidden-xs hidden-sm">
            <a href="img/icmlW23.png">
              <img class="media-object" src="img/icmlW23.png"  style="max-width:250px;" alt="npj">
            </a>
          </div>
          <div class="media-body">
            <h4 class="media-heading"><strong>CroSSL: Cross-modal Self-Supervised Learning for Time-series through Latent Masking</strong></h4>
            <p>Shohreh Deldari, <i>Dimitris Spathis</i>, Mohammad Malekzadeh, Fahim Kawsar, Flora Salim, Akhil Mathur <br>
            <em> ACM Conference on Web Search and Data Mining <a href="https://dl.acm.org/doi/10.1145/3616855.3635795"
>(WSDM'24)</a> </em> Merida, Mexico <br>also presented in: <em>ICML Machine Learning for Multimodal Health Data workshop, Hawaii, USA</em> <br>
                <div class="btn-group-sm">
                  <a href="https://dl.acm.org/doi/10.1145/3616855.3635795"
                  class="btn btn-default"><i class="fa fa-link fa-lg"></i> DOI </a>
                  <a href="https://dl.acm.org/doi/pdf/10.1145/3616855.3635795?casa_token=WS8UStZ3jKwAAAAA:5Py3Tb5uGG_v23SiaKZN0SP6MQExKLSWuFUF_oskhl1BO7fHUTMaLdKQ9FEnx2q19VLJprdxm0XutA"
                  class="btn btn-default"><i class="fa fa-file-pdf-o fa-lg"></i> PDF</a>
                  <a href="https://github.com/dr-bell/CroSSL"
                class="btn btn-default"><i class="fa fa-github fa-lg"></i> Code</a>
                  <a href="https://slideslive.com/39006577"
                  class="btn btn-default"><i class="fa fa-video-camera fa-lg"></i> ICMLw video (10mins)</a>
                </div>     
          </div>
        </div>  

                 <!-- WACV 2024 -->
                 <div class="media">
                  <div class="media-left media-middle hidden-xs hidden-sm">
                    <a href="img/kaizen.png">
                      <img class="media-object" src="img/kaizen.png"  style="max-width:250px;" alt="npj">
                    </a>
                  </div>
                  <div class="media-body">
                    <h4 class="media-heading"><strong>Kaizen: Practical self-supervised continual learning with continual fine-tuning</strong></h4>
                    <p>Chi Ian Tang, Lorena Qendro, <i>Dimitris Spathis</i>, Fahim Kawsar, Cecilia Mascolo, Akhil Mathur
                      <br>
                    <em> IEEE/CVF Winter Conference on Applications of Computer Vision <a href="https://dl.acm.org/doi/10.1145/3616855.3635795"
        >(WACV'24)</a>,</em> Hawaii, USA<br>
                        <div class="btn-group-sm">
                          <a href="https://openaccess.thecvf.com/content/WACV2024/papers/Tang_Kaizen_Practical_Self-Supervised_Continual_Learning_With_Continual_Fine-Tuning_WACV_2024_paper.pdf"
                          class="btn btn-default"><i class="fa fa-link fa-lg"></i> DOI </a>
                          <a href="https://openaccess.thecvf.com/content/WACV2024/papers/Tang_Kaizen_Practical_Self-Supervised_Continual_Learning_With_Continual_Fine-Tuning_WACV_2024_paper.pdf"
                          class="btn btn-default"><i class="fa fa-file-pdf-o fa-lg"></i> PDF</a>
                          <a href="https://openaccess.thecvf.com/content/WACV2024/supplemental/Tang_Kaizen_Practical_Self-Supervised_WACV_2024_supplemental.pdf"
                          class="btn btn-default"><i class="fa fa-file-pdf-o fa-lg"></i> PDF Suppl.</a>
                          <a href="https://github.com/dr-bell/kaizen"
                        class="btn btn-default"><i class="fa fa-github fa-lg"></i> Code</a>
                        </div>     
                  </div>
                </div>

                <!-- CIKM 2024 -->
                <div class="media">
                  <div class="media-left media-middle hidden-xs hidden-sm">
                    <a href="img/cikm24.png">
                      <img class="media-object" src="img/cikm24.png"  style="max-width:250px;" alt="npj">
                    </a>
                  </div>
                  <div class="media-body">
                    <h4 class="media-heading"><strong>StatioCL: Contrastive Learning for Time Series via Non-Stationary and Temporal Contrast</strong></h4>
                    <p>Yu Wu, Ting Dang, <i>Dimitris Spathis</i>, Hong Jia, Cecilia Mascolo <br>
                    <em>ACM International Conference on Information and Knowledge Management
                      <a href="https://dl.acm.org/doi/10.1145/3627673.3679732"
                        > (CIKM'24)</a></em>, Boise, USA <br>
                    <div class="btn-group-sm">
                        <a href="https://dl.acm.org/doi/10.1145/3627673.3679732"
                        class="btn btn-default"><i class="fa fa-link fa-lg"></i> DOI </a>
                        <a href="https://dl.acm.org/doi/pdf/10.1145/3627673.3679732"
                        class="btn btn-default"><i class="fa fa-file-pdf-o fa-lg"></i> PDF</a>
                         </p>
                      </div>
                 </div>

                  <!-- HotMobile 2024 -->
                  <div class="media">
                    <div class="media-left media-middle hidden-xs hidden-sm">
                      <a href="img/optibreath.png">
                        <img class="media-object" src="img/optibreath.png"  style="max-width:250px;" alt="npj">
                      </a>
                    </div>
                    <div class="media-body">
                      <h4 class="media-heading"><strong>OptiBreathe: An Earable-based PPG System for Continuous Respiration Rate, Breathing Phase, and Tidal Volume Monitoring</strong></h4>
                      <p>Julia Romero, Andrea Ferlini, <i>Dimitris Spathis</i>, Ting Dang, Katayoun Farrahi, Fahim Kawsar, Alessandro Montanari
                        <br>
                      <em> Intl. Workshop on Mobile Computing Systems and Applications <a href="https://dl.acm.org/doi/abs/10.1145/3638550.3641136"
          >(HotMobile'24)</a>,</em> San Diego, USA<br>
                          <div class="btn-group-sm">
                            <a href="https://dl.acm.org/doi/abs/10.1145/3638550.3641136"
                            class="btn btn-default"><i class="fa fa-link fa-lg"></i> DOI </a>
                            <a href="https://dl.acm.org/doi/pdf/10.1145/3638550.3641136"
                            class="btn btn-default"><i class="fa fa-file-pdf-o fa-lg"></i> PDF</a>
                          </div>     
                    </div>
                  </div> 

         
                  
                  
                   <!-- HCRL Kaizen 2024 -->
                 <div class="media">
                  <div class="media-left media-middle hidden-xs hidden-sm">
                    <a href="img/kaizenHCRL.png">
                      <img class="media-object" src="img/kaizenHCRL.png"  style="max-width:250px;" alt="npj">
                    </a>
                  </div>
                  <div class="media-body">
                    <h4 class="media-heading"><strong>Balancing Continual Learning and Fine-tuning for Human Activity Recognition</strong></h4>
                    <p>Chi Ian Tang, Lorena Qendro, <i>Dimitris Spathis</i>, Fahim Kawsar, Cecilia Mascolo, Akhil Mathur
                      <br>
                    <em> AAAI Human-centric Representation Learning workshop <a href="https://arxiv.org/abs/2401.02255"
        >(HCRL @ AAAI'24)</a>,</em> Vancouver, Canada<br>
                        <div class="btn-group-sm">
                          <a href="https://arxiv.org/abs/2401.02255"
                          class="btn btn-default"><i class="fa fa-link fa-lg"></i> DOI </a>
                          <a href="https://arxiv.org/pdf/2401.02255.pdf"
                          class="btn btn-default"><i class="fa fa-file-pdf-o fa-lg"></i> PDF</a>
                          <a href="https://github.com/dr-bell/kaizen"
                        class="btn btn-default"><i class="fa fa-github fa-lg"></i> Code</a>
                        </div>     
                  </div>
                </div>  


          <h3>2023</h3>


       

         <!-- MobileHCI 2023 -->
         <div class="media">
          <div class="media-left media-middle hidden-xs hidden-sm">
            <a href="img/mobilehci23.png">
              <img class="media-object" src="img/mobilehci23.png"  style="max-width:250px;" alt="npj">
            </a>
          </div>
          <div class="media-body">
            <h4 class="media-heading"><strong>The State of Algorithmic Fairness in Mobile Human-Computer
              Interaction</strong></h4>
            <p>Sofia Yfantidou, Marios Constantinides, <i>Dimitris Spathis</i>, Athena Vakali, Daniele Quercia, Fahim Kawsar <br>
            <em>ACM International Conference on Mobile Human-Computer Interaction<a href="https://arxiv.org/pdf/2307.12075.pdf"
              >  (MobileHCI'23),</a> </em> Athens, Greece<br>
                <div class="btn-group-sm">
                  <a href="https://arxiv.org/pdf/2307.12075.pdf"
                  class="btn btn-default"><i class="fa fa-link fa-lg"></i> DOI </a>
                  <a href="https://arxiv.org/pdf/2307.12075.pdf"
                  class="btn btn-default"><i class="fa fa-file-pdf-o fa-lg"></i> PDF</a>
                  <a href="https://youtu.be/UQ7IWfVOjKI?si=svRgilxiUAmyJn-C"
                  class="btn btn-default"><i class="fa fa-video-camera fa-lg"></i> Video (3mins)</a>
                </div>     
          </div>
        </div>  

         <!-- Royal Society 2023 -->
         <div class="media">
          <div class="media-left media-middle hidden-xs hidden-sm">
            <a href="img/royal.png">
              <img class="media-object" src="img/royal.png"  style="max-width:250px;" alt="npj">
            </a>
          </div>
          <div class="media-body">
            <h4 class="media-heading"><strong>Human-centred artificial intelligence for mobile health sensing: challenges and opportunities</strong></h4>
            <p>Ting Dang, <i>Dimitris Spathis</i>, Abhirup Ghosh, Cecilia Mascolo <br>
            <em> <a href="https://royalsocietypublishing.org/doi/full/10.1098/rsos.230806"
>Royal Society Open Science</a> </em><br>
                <div class="btn-group-sm">
                  <a href="https://royalsocietypublishing.org/doi/full/10.1098/rsos.230806"
                  class="btn btn-default"><i class="fa fa-link fa-lg"></i> DOI </a>
                  <a href="https://royalsocietypublishing.org/doi/pdf/10.1098/rsos.230806"
                  class="btn btn-default"><i class="fa fa-file-pdf-o fa-lg"></i> PDF</a>
                  
                </div>     
          </div>
        </div>  

        <!-- MLHC 2023 (Yu's 2nd paper) -->
        <div class="media">
          <div class="media-left media-middle hidden-xs hidden-sm">
            <a href="img/mlhc23.png">
              <img class="media-object" src="img/mlhc23.png"  style="max-width:250px;" alt="npj">
            </a>
          </div>
          <div class="media-body">
            <h4 class="media-heading"><strong>UDAMA: Unsupervised Domain Adaptation through
              Multi-discriminator Adversarial Training with Noisy Labels
              Improves Cardio-fitness Prediction</strong></h4>
            <p>Yu Wu, <i>Dimitris Spathis</i>, Hong Jia, Ignacio Perez-Pozuelo, Tomas I Gonzales, Soren Brage, Nicholas Wareham, Cecilia Mascolo <br>
            <em>Machine Learning for Healthcare<a href="https://static1.squarespace.com/static/59d5ac1780bd5ef9c396eda6/t/64d1a853a6742348f6a5f56c/1691461716532/ID136_Research+Paper_2023.pdf"
                > (MLHC'23)</a></em>, New York, USA <br>
            <div class="btn-group-sm">
                <a href="https://static1.squarespace.com/static/59d5ac1780bd5ef9c396eda6/t/64d1a853a6742348f6a5f56c/1691461716532/ID136_Research+Paper_2023.pdf"
                class="btn btn-default"><i class="fa fa-link fa-lg"></i> DOI </a>
                <a href="https://static1.squarespace.com/static/59d5ac1780bd5ef9c396eda6/t/64d1a853a6742348f6a5f56c/1691461716532/ID136_Research+Paper_2023.pdf"
                class="btn btn-default"><i class="fa fa-file-pdf-o fa-lg"></i> PDF</a>
                <a href="https://www.youtube.com/watch?v=5ndwC1FnlaU&ab_channel=MachineLearningforHealthcare"
                  class="btn btn-default"><i class="fa fa-video-camera fa-lg"></i> Video (3mins)</a>
                <a href="https://github.com/yvonneywu/UDAMA"
                class="btn btn-default"><i class="fa fa-github fa-lg"></i> Code</a> </p>
              </div>
         </div>
      </div>


    <!-- KDD 2023 -->
        <div class="media">
          <div class="media-left media-middle hidden-xs hidden-sm">
            <a href="img/kdd23.png">
              <img class="media-object" src="img/kdd23.png"  style="max-width:250px;" alt="npj">
            </a>
          </div>
          <div class="media-body">
            <h4 class="media-heading"><strong>Conditional Neural ODE Processes for Individual Disease Progression Forecasting: A Case Study on COVID-19</strong></h4>
            <p>Ting Dang, Jing Han, Tong Xia, Erika Bondareva, Chloë Siegele-Brown, Jagmohan Chauhan, Andreas Grammenos, <i>Dimitris Spathis</i>, Pietro Cicuta, Cecilia Mascolo <br>
            <em>International Conference on Knowledge Discovery and Data Mining<a href="https://mobile-systems.cl.cam.ac.uk/papers/kdd23.pdf"
              >
(KDD'23)</a></em>, Long Beach, USA <br>
                <div class="btn-group-sm">
                  <a href="https://dl.acm.org/doi/10.1145/3580305.3599792"
                  class="btn btn-default"><i class="fa fa-link fa-lg"></i> DOI </a>
                  <a href="https://mobile-systems.cl.cam.ac.uk/papers/kdd23.pdf"
                  class="btn btn-default"><i class="fa fa-file-pdf-o fa-lg"></i> PDF</a>
                  <a href="https://youtu.be/2WqMoT2sgsM?si=3tGwO474us4TTltu"
                  class="btn btn-default"><i class="fa fa-video-camera fa-lg"></i> Video (2mins)</a>
                </div>     
          </div>
        </div>

        <!-- arxiv Sofia 2023 
        <div class="media">
          <div class="media-left media-middle hidden-xs hidden-sm">
            <a href="img/arxiv23.png">
              <img class="media-object" src="img/arxiv23.png"  style="max-width:250px;" alt="npj">
            </a>
          </div>
          <div class="media-body">
            <h4 class="media-heading"><strong>Beyond Accuracy: A Critical Review of Fairness in Machine Learning for Mobile and Wearable Computing</strong></h4>
            <p>Sofia Yfantidou, Marios Constantinides, <i>Dimitris Spathis</i>, Athena Vakali, Daniele Quercia, Fahim Kawsar <br>
            <em><a href="https://arxiv.org/abs/2303.15585"
              >arXiv preprint </em><br>
                <div class="btn-group-sm">
                  <a href="https://arxiv.org/abs/2303.15585"
                  class="btn btn-default"><i class="fa fa-link fa-lg"></i> DOI </a>
                  <a href="https://arxiv.org/pdf/2303.15585"
                  class="btn btn-default"><i class="fa fa-file-pdf-o fa-lg"></i> PDF</a>
                </div>     
          </div>
        </div>

        -->

        <!-- Zenodo  2023 -->
        <div class="media">
          <div class="media-left media-middle hidden-xs hidden-sm">
            <a href="img/zenodo23.png">
              <img class="media-object" src="img/zenodo23.png"  style="max-width:250px;" alt="npj">
            </a>
          </div>
          <div class="media-body">
            <h4 class="media-heading"><strong>Recent Advances, Applications and Open Challenges in Machine Learning for Health: Reflections from Research Roundtables at ML4H 2022 Symposium</strong></h4>
            <p>Stefan Hegselmann, Helen Zhou, Yuyin Zhou, Jennifer Chien, Sujay Nagaraj, Neha Hulkund, Shreyas Bhave, Michael Oberst ... <i>Dimitris Spathis</i>, Jun Seita, Bastiaan Quast, Megan Coffee, Collin Stultz, Irene Y Chen, Shalmali Joshi, Girmaw Abebe Tadesse <br>
            <em><a href="https://www.researchgate.net/profile/Megan-Coffee/publication/371119938_ML4H_2022_Research_Roundtables-1/links/64737a306fb1d1682b165829/ML4H-2022-Research-Roundtables-1.pdf"
              >Technical report </em><br>
                <div class="btn-group-sm">
                  <a href="https://doi.org/10.5281/zenodo.7951122"
                  class="btn btn-default"><i class="fa fa-link fa-lg"></i> DOI </a>
                  <a href="https://www.researchgate.net/profile/Megan-Coffee/publication/371119938_ML4H_2022_Research_Roundtables-1/links/64737a306fb1d1682b165829/ML4H-2022-Research-Roundtables-1.pdf"
                  class="btn btn-default"><i class="fa fa-file-pdf-o fa-lg"></i> PDF</a>
                </div>     
          </div>
        </div>

         <!-- JMIR 2023 -->
        <div class="media">
          <div class="media-left media-middle hidden-xs hidden-sm">
            <a href="img/jmir23.png">
              <img class="media-object" src="img/jmir23.png"  style="max-width:250px;" alt="npj">
            </a>
          </div>
          <div class="media-body">
            <h4 class="media-heading"><strong>Evaluating Listening Performance for COVID-19 Detection by Clinicians and Machine Learning: A Comparative Study</strong></h4>

            <p>Jing Han, Marco Montagna, Andreas Grammenos, Tong Xia, Erika Bondareva, Chloë Siegele-Brown, Jagmohan Chauhan, Ting Dang, <i>Dimitris Spathis</i>, Andres Floto, Pietro Cicuta, Cecilia Mascolo <br>
            <em><a href="https://www.jmir.org/2023/1/e44804/"
              >Journal of Medical Internet Research (JMIR)</a></em>, 25<br>
                <div class="btn-group-sm">
                  <a href="https://www.jmir.org/2023/1/e44804/"
                  class="btn btn-default"><i class="fa fa-link fa-lg"></i> DOI </a>
                  <a href="https://www.jmir.org/2023/1/e44804/PDF"
                  class="btn btn-default"><i class="fa fa-file-pdf-o fa-lg"></i> PDF</a>
                </div>     
          </div>
        </div>

        <!-- Frontiers 2023 -->
        <div class="media">
          <div class="media-left media-middle hidden-xs hidden-sm">
            <a href="img/frontiers23.png">
              <img class="media-object" src="img/frontiers23.png"  style="max-width:250px;" alt="npj">
            </a>
          </div>
          <div class="media-body">
            <h4 class="media-heading"><strong>A Summary of the ComParE COVID-19 Challenges</strong></h4>

            <p>Alican Akman, Harry Coppock, Christian Bergler, Maurice Gerczuk, Chloë Brown, Jagmohan Chauhan, Andreas Grammenos, Apinan Hasthanasombat, <i>Dimitris Spathis</i>, Tong Xia, Pietro Cicuta, Jing Han, Shahin Amiriparian, Alice Baird, Lukas Stappen, Sandra Ottl, Panagiotis Tzirakis, Anton Batliner, Cecilia Mascolo, Björn Wolfgang Schuller <br>
            <em><a href="https://www.frontiersin.org/articles/10.3389/fdgth.2023.1058163/full"
              >Frontiers in Digital Health</a></em><br>
                <div class="btn-group-sm">
                  <a href="https://www.frontiersin.org/articles/10.3389/fdgth.2023.1058163/full"
                  class="btn btn-default"><i class="fa fa-link fa-lg"></i> DOI </a>
                  <a href="https://www.frontiersin.org/articles/10.3389/fdgth.2023.1058163/pdf"
                  class="btn btn-default"><i class="fa fa-file-pdf-o fa-lg"></i> PDF</a>
                </div>     
          </div>
        </div>




          <h3>2022</h3>

          <!-- Nat Dig Med 2022 -->
      	<div class="media">
  			  <div class="media-left media-middle hidden-xs hidden-sm">
  			    <a href="img/npj22fitness.png">
  			      <img class="media-object" src="img/npj22fitness.png"  style="max-width:250px;" alt="npj">
  			    </a>
  			  </div>
  			  <div class="media-body">
  			    <h4 class="media-heading"><strong>Longitudinal cardio-respiratory fitness prediction through wearables in free-living environments</strong></h4>
  			    <p><i>Dimitris Spathis*</i>, Ignacio Perez-Pozuelo*, Tomas I. Gonzales, Yu Wu, Soren Brage, Nicholas Wareham, Cecilia Mascolo <span style="font-size:13px">(*equal contribution)</span> <br>
  			    <em><a href="https://www.nature.com/articles/s41746-022-00719-1"
                >Nature Digital Medicine</a></em>, 5(176) <br>
                <font class="caps" color=#f39c12><i class="fa fa-trophy fa-xs"></i> Altmetric Top 5% of all research outputs</font>
        		    <div class="btn-group-sm">
                  <a href="https://www.nature.com/articles/s41746-022-00719-1"
                  class="btn btn-default"><i class="fa fa-link fa-lg"></i> DOI </a>
                  <a href="https://www.nature.com/articles/s41746-022-00719-1.pdf"
                  class="btn btn-default"><i class="fa fa-file-pdf-o fa-lg"></i> PDF</a>
                  <a href="https://github.com/sdimi/cardiofitness"
                  class="btn btn-default"><i class="fa fa-github fa-lg"></i> Code</a> </p>
                </div>		 
  		    </div>
        </div>





        <!-- Nat Dig Med 2022 -->
      	<div class="media">
			  <div class="media-left media-middle hidden-xs hidden-sm">
			    <a href="img/npj22.png">
			      <img class="media-object" src="img/npj22.png"  style="max-width:250px;" alt="npj">
			    </a>
			  </div>
			  <div class="media-body">
			    <h4 class="media-heading"><strong>Sounds of COVID-19: exploring realistic performance of audio-based digital testing</strong></h4>
			    <p>Jing Han*, Tong Xia*, <i>Dimitris Spathis</i>, Erika Bondareva, Chloë Brown, Jagmohan Chauhan, Ting Dang, Andreas Grammenos, Apinan Hasthanasombat, Andres Floto, Pietro Cicuta, Cecilia Mascolo <br>
			    <em><a href="https://www.nature.com/articles/s41746-021-00553-x"
              >Nature Digital Medicine</a></em>, 5(16) <br>
			    <div class="btn-group-sm">
              <a href="https://www.nature.com/articles/s41746-021-00553-x"
              class="btn btn-default"><i class="fa fa-link fa-lg"></i> DOI </a>
              <a href="https://www.nature.com/articles/s41746-021-00553-x.pdf"
              class="btn btn-default"><i class="fa fa-file-pdf-o fa-lg"></i> PDF</a>
              <a href="https://healthcommunity.nature.com/posts/sounds-of-covid-19-exploring-realistic-performance-of-audio-based-digital-testing?badge_id=712-npj-digital-medicine"
              class="btn btn-default"><i class="fa fa-newspaper-o fa-lg"></i> Blog post</a>
              <a href="https://github.com/cam-mobsys/covid19-sounds-npjDM"
              class="btn btn-default"><i class="fa fa-github fa-lg"></i> Code</a> </p>
            </div>
			 
		</div>
    </div>

          <!-- Cell Patterns 2022 -->
          <div class="media">
			  <div class="media-left media-middle hidden-xs hidden-sm">
			    <a href="img/patterns22.png">
			      <img class="media-object" border="0" src="img/patterns22.png" style="max-width:250px;">
			    </a>
			  </div>
			  <div class="media-body">
			    <h4 class="media-heading"><strong>Breaking away from labels: the promise of self-supervised machine learning in intelligent health</strong></h4>
			    <p><i>Dimitris Spathis</i>, Ignacio Perez-Pozuelo, Laia Marques-Fernandez, Cecilia Mascolo <br>
			    <em><a href="https://www.cell.com/patterns/fulltext/S2666-3899(21)00284-1"
              >Cell Patterns</a></em>, 3(2) <br>
			    <div class="btn-group-sm">
              <a href="https://www.cell.com/patterns/fulltext/S2666-3899(21)00284-1"
              class="btn btn-default"><i class="fa fa-link fa-lg"></i> DOI </a>
              <a href="https://www.cell.com/action/showPdf?pii=S2666-3899%2821%2900284-1"
              class="btn btn-default"><i class="fa fa-file-pdf-o fa-lg"></i> PDF</a></p>
            </div>
			  </div>
		</div>


          <!-- Sci Rep 2022 -->
          <div class="media">
			  <div class="media-left media-middle hidden-xs hidden-sm">
			    <a href="img/scirep22.png">
			      <img class="media-object" src="img/scirep22.png"  style="max-width:250px;" alt="npj">
			    </a>
			  </div>
			  <div class="media-body">
			    <h4 class="media-heading"><strong>Detecting sleep outside the clinic using wearable heart rate devices</strong></h4>
			    <p>Ignacio Perez-Pozuelo, Marius Posa, <i>Dimitris Spathis</i>, Kate Westgate, Nicholas Wareham, Cecilia Mascolo, Soren Brage, Joao Palotti <br>
			    <em><a href="https://www.nature.com/articles/s41598-022-11792-7"
              >Scientific Reports</a></em>, 12 (7956) <br>
			    <div class="btn-group-sm">
              <a href="https://www.nature.com/articles/s41598-022-11792-7"
              class="btn btn-default"><i class="fa fa-link fa-lg"></i> DOI </a>
              <a href="https://www.nature.com/articles/s41598-022-11792-7.pdf"
              class="btn btn-default"><i class="fa fa-file-pdf-o fa-lg"></i> PDF</a>
              <a href="https://github.com/HypnosPy/HypnosPy/"
              class="btn btn-default"><i class="fa fa-github fa-lg"></i> Code</a> </p>
            </div>
			  </div>
		</div>


          <!-- JMIR 2022 -->
          <div class="media">
			  <div class="media-left media-middle hidden-xs hidden-sm">
			    <a href="img/jmir22.png">
			      <img class="media-object" src="img/jmir22.png"  style="max-width:250px;" alt="npj">
			    </a>
			  </div>
			  <div class="media-body">
			    <h4 class="media-heading"><strong>Exploring Longitudinal Cough, Breath, and Voice Data for COVID-19 Progression Prediction via Sequential Deep Learning: Model Development and Validation</strong></h4>
			    <p>Ting Dang, Jing Han, Tong Xia, <i>Dimitris Spathis</i>, Erika Bondareva, Chloë Brown, Jagmohan Chauhan, Andreas Grammenos, Apinan Hasthanasombat, Andres Floto, Pietro Cicuta, Cecilia Mascolo <br>
			    <em><a href="https://www.jmir.org/2022/6/e37004"
              >Journal of Medical Internet Research (JMIR)</a></em>, 24(6) <br>
			    <div class="btn-group-sm">
              <a href="https://www.jmir.org/2022/6/e37004"
              class="btn btn-default"><i class="fa fa-link fa-lg"></i> DOI </a>
              <a href="https://www.jmir.org/2022/6/e37004/PDF"
              class="btn btn-default"><i class="fa fa-file-pdf-o fa-lg"></i> PDF</a>
              <a href="https://covid-19-sounds.org/en/blog/longitudinal_covid_jmir.html"
              class="btn btn-default"><i class="fa fa-newspaper-o fa-lg"></i> Blog post</a> </p>
            </div>
			  </div>
		</div>

         

          <!-- JPSP 2022 -->

          <div class="media">
			  <div class="media-left media-middle hidden-xs hidden-sm">
			    <a href="img/jpsp22.png">
			      <img class="media-object" src="img/jpsp22.png"  style="max-width:250px;" alt="npj">
			    </a>
			  </div>
			  <div class="media-body">
			    <h4 class="media-heading"><strong>Universals and variations in musical preferences: A study of preferential reactions to Western music in 53 countries</strong></h4>
			    <p>David Greenberg, Sebastian Wride, Daniel Snowden, <i>Dimitris Spathis</i>, Jeff Potter, Jason Rentfrow <br>
			    <em><a href="https://psycnet.apa.org/doiLanding?doi=10.1037%2Fpspp0000397"
              >Journal of Personality and Social Psychology</a></em>, 122(2) <br>
              <font class="caps" color=#f39c12><i class="fa fa-trophy fa-xs"></i> Altmetric Top 5% of all research outputs</font>
			    <div class="btn-group-sm">
              <a href="https://psycnet.apa.org/doiLanding?doi=10.1037%2Fpspp0000397"
              class="btn btn-default"><i class="fa fa-link fa-lg"></i> DOI </a>
              <a href="https://www.gwern.net/docs/psychology/personality/2022-greenberg.pdf"
              class="btn btn-default"><i class="fa fa-file-pdf-o fa-lg"></i> PDF</a>
              <a href="https://osf.io/8dxtj/"
              class="btn btn-default"><i class="fa fa-github fa-lg"></i> Code</a>
              
               </p>
            </div>
			  </div>
		</div>


		  <!-- ML4H 2022 (my paper) -->
      	<div class="media">
			  <div class="media-left media-middle hidden-xs hidden-sm">
			    <a href="img/ml4h22.png">
			      <img class="media-object" src="img/ml4h22.png"  style="max-width:250px;" alt="npj">
			    </a>
			  </div>
			  <div class="media-body">
			    <h4 class="media-heading"><strong>Looking for Out-of-Distribution Environments in Multi-center Critical Care Data</strong></h4>
			    <p><i>Dimitris Spathis</i>, Stephanie Hyland <br>
			    <em>Machine Learning for Health<a href="https://arxiv.org/abs/2205.13398"
              >(ML4H'22)</a></em>, New Orleans, USA <br>
			    <div class="btn-group-sm">
              <a href="https://arxiv.org/abs/2205.13398"
              class="btn btn-default"><i class="fa fa-link fa-lg"></i> DOI </a>
              <a href="https://arxiv.org/pdf/2205.13398.pdf"
              class="btn btn-default"><i class="fa fa-file-pdf-o fa-lg"></i> PDF</a>
            </div>
			 </div>
		</div>


    <!-- ML4H 2022 (Yu's paper) -->
        <div class="media">
        <div class="media-left media-middle hidden-xs hidden-sm">
          <a href="img/ml4h22(yu).png">
            <img class="media-object" src="img/ml4h22(yu).png"  style="max-width:250px;" alt="npj">
          </a>
        </div>
        <div class="media-body">
          <h4 class="media-heading"><strong>Turning Silver into Gold: Domain Adaptation with Noisy Labels for Wearable Cardio-Respiratory Fitness Prediction</strong></h4>
          <p>Yu Wu, <i>Dimitris Spathis</i>, Hong Jia, Ignacio Perez-Pozuelo, Tomas I Gonzales, Soren Brage, Nicholas Wareham, Cecilia Mascolo <br>
          <em>Machine Learning for Health<a href="https://arxiv.org/abs/2211.10475"
              >(ML4H'22)</a></em>, New Orleans, USA <br>
          <div class="btn-group-sm">
              <a href="https://arxiv.org/abs/2211.10475"
              class="btn btn-default"><i class="fa fa-link fa-lg"></i> DOI </a>
              <a href="https://arxiv.org/pdf/2211.10475.pdf"
              class="btn btn-default"><i class="fa fa-file-pdf-o fa-lg"></i> PDF</a>
            </div>
       </div>
    </div>

        

          <!-- HASCA @ Ubicomp 2022 -->

          <div class="media">
			  <div class="media-left media-middle hidden-xs hidden-sm">
			    <a href="img/hasca22.png">
			      <img class="media-object" src="img/hasca22.png"  style="max-width:250px;" alt="npj">
			    </a>
			  </div>
			  <div class="media-body">
			    <h4 class="media-heading"><strong>Investigating Domain-agnostic Performance in Activity Recognition using Accelerometer Data</strong></h4>
			    <p>Apinan Hasthanasombat, Abhirup Ghosh, <i>Dimitris Spathis</i>, Cecilia Mascolo <br>
			    <em>UbiComp workshop on Human Activity Sensing Corpus & Applications <a href="https://doi.org/10.1145/3544793.3560398"
              >(HASCA @ UbiComp'22)</a></em>, Cambridge, UK <br>
			    <div class="btn-group-sm">
              <a href="https://doi.org/10.1145/3544793.3560398"
              class="btn btn-default"><i class="fa fa-link fa-lg"></i> DOI </a>
              <a href="https://mobile-systems.cl.cam.ac.uk/papers/hasca22.pdf"
              class="btn btn-default"><i class="fa fa-file-pdf-o fa-lg"></i> PDF</a>
              
               </p>
            </div>
			  </div>
		</div>


          <h3>2021</h3>

          <!-- NeurIPS 2021 -->
          <div class="media">
			  <div class="media-left media-middle hidden-xs hidden-sm">
			    <a href="img/neurips21.png">
			      <img class="media-object" src="img/neurips21.png"  style="max-width:250px;" alt="npj">
			    </a>
			  </div>
			  <div class="media-body">
			    <h4 class="media-heading"><strong>COVID-19 Sounds: A Large-Scale Audio Dataset for Digital Respiratory Screening</strong></h4>
			    <p>Tong Xia*, <i>Dimitris Spathis*</i>, Chloe Brown, Jagmohan Chauhan, Andreas Grammenos, Jing Han, Apinan Hasthanasombat, Erika Bondareva, Ting Dang, Andres Floto, Pietro Cicuta, Cecilia Mascolo <br>
			    <em>Neural Information Processing Systems<a href="https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/hash/e2c0be24560d78c5e599c2a9c9d0bbd2-Abstract-round2.html"
              > (NeurIPS'21)</a></em>, Datasets and Benchmarks Track <br>
			    <div class="btn-group-sm">
              <a href="https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/hash/e2c0be24560d78c5e599c2a9c9d0bbd2-Abstract-round2.html"
              class="btn btn-default"><i class="fa fa-link fa-lg"></i> DOI </a>
              <a href="https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/file/e2c0be24560d78c5e599c2a9c9d0bbd2-Paper-round2.pdf"
              class="btn btn-default"><i class="fa fa-file-pdf-o fa-lg"></i> PDF</a>
              <a href="https://www.covid-19-sounds.org/blog/neurips_dataset"
              class="btn btn-default"><i class="fa fa-newspaper-o fa-lg"></i> Blog post</a>
              <a href="https://github.com/cam-mobsys/covid19-sounds-neurips"
              class="btn btn-default"><i class="fa fa-github fa-lg"></i> Code</a> 
              <a href="https://slideslive.com/38969500/covid19-sounds-a-largescale-audio-dataset-for-digital-respiratory-screening?ref=recommended"
              class="btn btn-default"><i class="fa fa-video-camera fa-lg"></i> Talk (4mins)</a>
          </p>
            </div>
		</div>
  </div>


          

          <!-- CHIL 2021 -->
            <div class="media">
			  <div class="media-left media-middle hidden-xs hidden-sm">
			    <a href="img/chil21.png">
			      <img class="media-object" src="img/chil21.png"  style="max-width:250px;" alt="npj">
			    </a>
			  </div>
			  <div class="media-body">
			    <h4 class="media-heading"><strong>Self-supervised transfer learning of physiological representations from free-living wearable data</strong></h4>
			    <p>Dimitris Spathis</i>, Ignacio Perez-Pozuelo, Soren Brage, Nicholas Wareham, Cecilia Mascolo <br>
			    <em>Conference on Health, Inference, and Learning<a href="https://dl.acm.org/doi/10.1145/3450439.3451863"
              > (CHIL'21)</a></em>, Virtual event, USA <br>
			    <div class="btn-group-sm">
              <a href="https://dl.acm.org/doi/10.1145/3450439.3451863"
              class="btn btn-default"><i class="fa fa-link fa-lg"></i> DOI </a>
              <a href="https://dl.acm.org/doi/pdf/10.1145/3450439.3451863"
              class="btn btn-default"><i class="fa fa-file-pdf-o fa-lg"></i> PDF</a>
              <a href="https://github.com/sdimi/Step2heart"
              class="btn btn-default"><i class="fa fa-github fa-lg"></i> Code</a> 
              <a href="https://www.chilconference.org/proceeding_P07.html"
              class="btn btn-default"><i class="fa fa-video-camera fa-lg"></i> Talk (6mins) </a>
          </p>
            </div>
		</div>
    </div>


          <!-- ICASSP 2021 -->

                      <div class="media">
			  <div class="media-left media-middle hidden-xs hidden-sm">
			    <a href="img/icassp21.png">
			      <img class="media-object" src="img/icassp21.png"  style="max-width:250px;" alt="npj">
			    </a>
			  </div>
			  <div class="media-body">
			    <h4 class="media-heading"><strong>Exploring Automatic COVID-19 Diagnosis via voice and symptoms from Crowdsourced Data</strong></h4>
			    <p>Jing Han, Chloë Brown*, Jagmohan Chauhan*, Andreas Grammenos*, Apinan Hasthanasombat*, <i>Dimitris Spathis</i>*, Tong Xia*, Pietro Cicuta, Cecilia Mascolo <br>
			    <em>International Conference on Acoustics, Speech, & Signal Processing<a href="https://doi.org/10.1109/ICASSP39728.2021.9414576"
              > (ICASSP'21)</a></em>, Toronto, Canada <br>
			    <div class="btn-group-sm">
              <a href="https://doi.org/10.1109/ICASSP39728.2021.9414576"
              class="btn btn-default"><i class="fa fa-link fa-lg"></i> DOI </a>
              <a href="https://arxiv.org/pdf/2102.05225.pdf"
              class="btn btn-default"><i class="fa fa-file-pdf-o fa-lg"></i> PDF</a>
              <a href="https://covid-19-sounds.org/blog/voice_covid_icassp"
              class="btn btn-default"><i class="fa fa-newspaper-o fa-lg"></i> Blog post</a>
          </p>
            </div>
		</div>
    </div>


   

          <!-- IMWUT 2021 -->

                      <div class="media">
			  <div class="media-left media-middle hidden-xs hidden-sm">
			    <a href="img/imwut21.png">
			      <img class="media-object" src="img/imwut21.png"  style="max-width:250px;" alt="npj">
			    </a>
			  </div>
			  <div class="media-body">
			    <h4 class="media-heading"><strong><em>SelfHAR</em>: Improving Human Activity Recognition through Self-training with Unlabeled Data</strong></h4>
			    <p>Chi Ian Tang, Ignacio Perez-Pozuelo*, <i>Dimitris Spathis</i>*, Soren Brage, Nicholas Wareham, Cecilia Mascolo <br>
			    <em>Proc. on Interactive, Mobile, Wearable and Ubiquitous Technologies<a href="https://doi.org/10.1145/3448112"
              > (IMWUT/Ubicomp'21)</a></em>, 5(1) <br>
			    <div class="btn-group-sm">
              <a href="https://doi.org/10.1145/3448112"
              class="btn btn-default"><i class="fa fa-link fa-lg"></i> DOI </a>
              <a href="https://dl.acm.org/doi/pdf/10.1145/3448112"
              class="btn btn-default"><i class="fa fa-file-pdf-o fa-lg"></i> PDF</a>
              <a href="https://github.com/iantangc/SelfHAR"
              class="btn btn-default"><i class="fa fa-github fa-lg"></i> Code</a> 
              <a href="https://youtu.be/WpZCiUXUNAo"
              class="btn btn-default"><i class="fa fa-play fa-lg"></i> Promo video (5mins)</a>
              <a href="https://youtu.be/BzBLSH13kzU"
              class="btn btn-default"><i class="fa fa-video-camera fa-lg"></i> Talk (13mins) </a>
          </p>
            </div>
		</div>
    </div>


          <!-- Interspeech 2021 -->

          <div class="media">
			  <div class="media-left media-middle hidden-xs hidden-sm">
			    <a href="img/interspeech21.png">
			      <img class="media-object" src="img/interspeech21.png"  style="max-width:250px;" alt="npj">
			    </a>
			  </div>
			  <div class="media-body">
			    <h4 class="media-heading"><strong><em>The INTERSPEECH 2021 Computational Paralinguistics Challenge</em>: COVID-19 Cough, COVID-19 Speech, Escalation & Primates</strong></h4>
			    <p>Björn W. Schuller, ... <i>Dimitris Spathis</i>, Tong Xia, Pietro Cicuta, Leon J. M. Rothkrantz, Joeri Zwerts, Jelle Treep, Casper Kaandorp <br>
			    <em>Conference of the International Speech Communication Association<a href="https://www.isca-speech.org/archive/interspeech_2021/schuller21_interspeech.html"
              > (Interspeech'21)</a></em>, Brno, Czechia <br>
			    <div class="btn-group-sm">
              <a href="https://www.isca-speech.org/archive/interspeech_2021/schuller21_interspeech.html"
              class="btn btn-default"><i class="fa fa-link fa-lg"></i> DOI </a>
              <a href="https://www.isca-speech.org/archive/pdfs/interspeech_2021/schuller21_interspeech.pdf"
              class="btn btn-default"><i class="fa fa-file-pdf-o fa-lg"></i> PDF</a>
              <a href="http://www.compare.openaudio.eu/now/"
              class="btn btn-default"><i class="fa fa-database fa-lg"></i> Dataset </a>
          </p>
            </div>
		</div>
    </div>

          
          <!-- JAMIA 2021 -->

          <div class="media">
			  <div class="media-left media-middle hidden-xs hidden-sm">
			    <a href="img/jamia21.png">
			      <img class="media-object" src="img/jamia21.png"  style="max-width:250px;" alt="npj">
			    </a>
			  </div>
			  <div class="media-body">
			    <h4 class="media-heading"><strong>Digital Phenotyping and Sensitive Health Data: Implications for Data Governance</strong></h4>
			    <p>Ignacio Perez-Pozuelo, <i>Dimitris Spathis</i>, Jordan Gifford-Moore, Jessica Morley, Josh Cowls <br>
			    <em><a href="https://academic.oup.com/jamia/advance-article/doi/10.1093/jamia/ocab012/6153954"
              >Journal of the American Medical Informatics Association</a></em>, 28(9) <br>
			    <div class="btn-group-sm">
              <a href="https://academic.oup.com/jamia/advance-article/doi/10.1093/jamia/ocab012/6153954"
              class="btn btn-default"><i class="fa fa-link fa-lg"></i> DOI </a>
              <a href="https://www.repository.cam.ac.uk/bitstream/handle/1810/316526/ocab012.pdf?sequence=4&isAllowed=y"
              class="btn btn-default"><i class="fa fa-file-pdf-o fa-lg"></i> PDF</a>
          </p>
            </div>
		</div>
    </div>


      

          <!-- MobileHCI 2021 -->

                    <div class="media">
        <div class="media-left media-middle hidden-xs hidden-sm">
          <a href="img/mobilehci21.png">
            <img class="media-object" src="img/mobilehci21.png"  style="max-width:250px;" alt="npj">
          </a>
        </div>
        <div class="media-body">
          <h4 class="media-heading"><strong>Anticipatory Detection of Compulsive Body-focused Repetitive Behaviors with Wearables</strong></h4>
          <p>Benjamin Searle, <i>Dimitris Spathis</i>, Marios Constantinides, Daniele Quercia, Cecilia Mascolo <br>
          <em>ACM International Conference on Mobile Human-Computer Interaction<a href="https://dl.acm.org/doi/10.1145/3447526.3472061"
              > (MobileHCI'21)</a></em>, Toulouse, France <br>
          <div class="btn-group-sm">
              <a href="https://dl.acm.org/doi/10.1145/3447526.3472061"
              class="btn btn-default"><i class="fa fa-link fa-lg"></i> DOI </a>
              <a href="https://dl.acm.org/doi/pdf/10.1145/3447526.3472061"
              class="btn btn-default"><i class="fa fa-file-pdf-o fa-lg"></i> PDF</a>
              <a href="https://github.com/Bhorda/BFRBAnticipationDataset"
              class="btn btn-default"><i class="fa fa-github fa-lg"></i> Code </a>
              <a href="https://medium.com/socialdynamics/skin-picking-and-hair-pulling-disorders-smartwatches-can-stop-965fb852dc6f"
              class="btn btn-default"><i class="fa fa-newspaper-o fa-lg"></i> Blog post</a>
              <a href="https://github.com/Bhorda/BFRBAnticipationDataset"
              class="btn btn-default"><i class="fa fa-database fa-lg"></i> Dataset </a>
          </p>
            </div>
    </div>
    </div>



          <!-- ML4H 2021 -->

                    <div class="media">
        <div class="media-left media-middle hidden-xs hidden-sm">
          <a href="img/ml4h21.png">
            <img class="media-object" src="img/ml4h21.png"  style="max-width:250px;" alt="npj">
          </a>
        </div>
        <div class="media-body">
          <h4 class="media-heading"><strong>Evaluating Contrastive Learning on Wearable Timeseries for Downstream Clinical Outcomes</strong></h4>
          <p>Kevalee Shah, <i>Dimitris Spathis</i>, Chi Ian Tang, Cecilia Mascolo <br>
          <em>Machine Learning for Health<a href="https://arxiv.org/abs/2111.07089"
              > (ML4H'21)</a></em>, Virtual event <br>
          <div class="btn-group-sm">
              <a href="https://arxiv.org/abs/2111.07089"
              class="btn btn-default"><i class="fa fa-link fa-lg"></i> DOI </a>
              <a href="https://arxiv.org/pdf/2111.07089.pdf"
              class="btn btn-default"><i class="fa fa-file-pdf-o fa-lg"></i> PDF</a>
          </p>
            </div>
    </div>
    </div>

          <!-- MobiCom 2021 -->

           <div class="media">
        <div class="media-left media-middle hidden-xs hidden-sm">
          <a href="img/mobicom21.png">
            <img class="media-object" src="img/mobicom21.png"  style="max-width:250px;" alt="npj">
          </a>
        </div>
        <div class="media-body">
          <h4 class="media-heading"><strong>Federated mobile sensing for activity recognition</strong></h4>
          <p>Stefanos Laskaridis, <i>Dimitris Spathis</i>, Mario Almeida <br>
          <em><a href="https://dl.acm.org/doi/abs/10.1145/3447993.3488031"
              >ACM International Conference on Mobile Computing and Networking (MobiCom)</a></em>, New Orleans, USA (tutorial) <br>
          <div class="btn-group-sm">
              <a href="https://dl.acm.org/doi/abs/10.1145/3447993.3488031"
              class="btn btn-default"><i class="fa fa-link fa-lg"></i> DOI </a>
              <a href="https://dl.acm.org/doi/pdf/10.1145/3447993.3488031?casa_token=sRVbM3EVRwsAAAAA:4VRt_cEajLs-dC81KAL8nhNqYnlplXadIjdkQ9FOFxG0c4pLjsaGRgECmxBXbTwJHPZS-VeWNO2q"
              class="btn btn-default"><i class="fa fa-file-pdf-o fa-lg"></i> PDF</a>
              <a href="https://gitlab.com/stevelaskaridis/federatedsensing-mobicom21"
              class="btn btn-default"><i class="fa fa-github fa-lg"></i> Code </a>
              <a href="https://federatedsensing.gitlab.io"
              class="btn btn-default"><i class="fa fa-newspaper-o fa-lg"></i> Project</a>
              <a href="https://youtu.be/HYSep0yZECc"
              class="btn btn-default"><i class="fa fa-video-camera fa-lg"></i> Talk (31mins) </a>
          </p>
            </div>
    </div>
    </div>

          <!-- Digital Health 2021 -->

          <div class="media">
        <div class="media-left media-middle hidden-xs hidden-sm">
          <a href="img/chapter21.png">
            <img class="media-object" src="img/chapter21.png"  style="max-width:250px;" alt="npj">
          </a>
        </div>
        <div class="media-body">
          <h4 class="media-heading"><strong>Wearables, smartphones and artificial intelligence for digital phenotyping and health</strong></h4>
          <p>Ignacio Perez-Pozuelo, <i>Dimitris Spathis</i>, Emma Clifton, Cecilia Mascolo <br>
          <em><a href="https://doi.org/fpfv"
              >Digital Health</a></em>, Chapter 3  <br>
          <div class="btn-group-sm">
              <a href="https://doi.org/fpfv"
              class="btn btn-default"><i class="fa fa-link fa-lg"></i> DOI </a>
              <a href="https://www.repository.cam.ac.uk/bitstream/handle/1810/313818/Elsevier%20Digital%20Health%20accepted%20version.pdf?sequence=1&isAllowed=y"
              class="btn btn-default"><i class="fa fa-file-pdf-o fa-lg"></i> PDF</a>
            
          </p>
            </div>
    </div>
    </div>


          <h3>2020</h3> 

          <!-- KDD 2020 -->

          <div class="media">
        <div class="media-left media-middle hidden-xs hidden-sm">
          <a href="img/kdd20.png">
            <img class="media-object" src="img/kdd20.png"  style="max-width:250px;" alt="npj">
          </a>
        </div>
        <div class="media-body">
          <h4 class="media-heading"><strong>Exploring Automatic Diagnosis of COVID-19 from Crowdsourced Respiratory Sound Data</strong></h4>
          <p>Chloë Brown*, Jagmohan Chauhan*, Andreas Grammenos*, Jing Han*, Apinan Hasthanasombat*, <i>Dimitris Spathis</i>*, Tong Xia*, Pietro Cicuta, Cecilia Mascolo <br>

          <em>International Conference on Knowledge Discovery and Data Mining<a href="https://dl.acm.org/doi/abs/10.1145/3447993.3488031"
              > (KDD'20)</a></em>, San Diego, USA <br>
          <font class="caps" color=#be1e2d><i class="fa fa-star fa-xs"></i> Oral presentation</font> <font class="caps" color=#f39c12><i class="fa fa-trophy fa-xs"></i> Cambridge University Hall of Fame Better Future Award</font>
          <div class="btn-group-sm">
              <a href="https://doi.org/10.1145/3394486.3412865"
              class="btn btn-default"><i class="fa fa-link fa-lg"></i> DOI </a>
              <a href="papers/KDD_Exploring_automatic_Brown_et_al.pdf"
              class="btn btn-default"><i class="fa fa-file-pdf-o fa-lg"></i> PDF</a>
              <a href="https://github.com/cam-mobsys/covid19-sounds-kdd20"
              class="btn btn-default"><i class="fa fa-github fa-lg"></i> Code </a>
              <a href="https://covid-19-sounds.org/blog/detect_covid_kdd"
              class="btn btn-default"><i class="fa fa-newspaper-o fa-lg"></i> Blog post</a>
              <a href="https://youtu.be/l8stvxjBjKs"
              class="btn btn-default"><i class="fa fa-video-camera fa-lg"></i> Talk (21mins) </a>
          </p>
            </div>
    </div>
    </div>


          

          <!-- Neurips-W (Spathis) 2020 -->

              <div class="media">
        <div class="media-left media-middle hidden-xs hidden-sm">
          <a href="img/neuripsw20a.png">
            <img class="media-object" src="img/neuripsw20a.png"  style="max-width:250px;" alt="npj">
          </a>
        </div>
        <div class="media-body">
          <h4 class="media-heading"><strong>Learning Generalizable Physiological Representations from Large-scale Wearable Data</strong></h4>
          <p>Dimitris Spathis</i>, Ignacio Perez-Pozuelo, Soren Brage, Nicholas Wareham, Cecilia Mascolo<br>
          NeurIPS Machine Learning for Mobile Health workshop <em><a href="https://sites.google.com/view/ml4mobilehealth-neurips-2020/home"
              >(ML4MH @ NeurIPS'20)</a></em>, Vancouver, Canada <br>
          <div class="btn-group-sm">
              <a href="https://arxiv.org/pdf/2011.04601.pdf"
              class="btn btn-default"><i class="fa fa-link fa-lg"></i> DOI </a>
              <a href="https://arxiv.org/pdf/2011.04601.pdf"
              class="btn btn-default"><i class="fa fa-file-pdf-o fa-lg"></i> PDF</a>
              <a href="https://github.com/sdimi/Step2heart"
              class="btn btn-default"><i class="fa fa-github fa-lg"></i> Code </a>
          </p>
            </div>
    </div>
    </div>

          <!-- Neurips-W (Tang) 2020 -->


              <div class="media">
        <div class="media-left media-middle hidden-xs hidden-sm">
          <a href="img/neuripsw20b.png">
            <img class="media-object" src="img/neuripsw20b.png"  style="max-width:250px;" alt="npj">
          </a>
        </div>
        <div class="media-body">
          <h4 class="media-heading"><strong>Exploring Contrastive Learning in Human Activity Recognition for Healthcare</strong></h4>
          <p>Chi Ian Tang, Ignacio Perez-Pozuelo, <i>Dimitris Spathis</i>, Cecilia Mascolo<br>
          NeurIPS Machine Learning for Mobile Health workshop <em><a href="https://sites.google.com/view/ml4mobilehealth-neurips-2020/home"
              >(ML4MH @ NeurIPS'20)</a></em>, Vancouver, Canada <br>
          <div class="btn-group-sm">
              <a href="https://arxiv.org/pdf/2011.11542.pdf"
              class="btn btn-default"><i class="fa fa-link fa-lg"></i> DOI </a>
              <a href="https://arxiv.org/pdf/2011.11542.pdf"
              class="btn btn-default"><i class="fa fa-file-pdf-o fa-lg"></i> PDF</a>
              <a href="https://github.com/iantangc/ContrastiveLearningHAR"
              class="btn btn-default"><i class="fa fa-github fa-lg"></i> Code </a>
          </p>
            </div>
    </div>
    </div>


          <h3>2019</h3> 


          <!-- KDD 2019 -->

               <div class="media">
        <div class="media-left media-middle hidden-xs hidden-sm">
          <a href="img/kdd19.png">
            <img class="media-object" src="img/kdd19.png"  style="max-width:250px;" alt="npj">
          </a>
        </div>
        <div class="media-body">
          <h4 class="media-heading"><strong>Sequence Multi-task Learning to Forecast Mental Wellbeing from Sparse Self-reported Data</strong></h4>
          <p><i>Dimitris Spathis</i>, Sandra Servia, Katayoun Farrahi, Cecilia Mascolo, Jason Rentfrow <br>

          <em>International Conference on Knowledge Discovery and Data Mining<a href="https://doi.org/10.1145/3292500.3330730"
              > (KDD'19)</a></em>, Anchorage, USA <br>
          <font class="caps" color=#be1e2d><i class="fa fa-star fa-xs"></i> Oral presentation (Top 6%)</font>
          <div class="btn-group-sm">
              <a href="https://doi.org/10.1145/3292500.3330730"
              class="btn btn-default"><i class="fa fa-link fa-lg"></i> DOI </a>
              <a href="papers/KDD_Sequence_multi_Spathis_et_al.pdf"
              class="btn btn-default"><i class="fa fa-file-pdf-o fa-lg"></i> PDF</a>
              <a href="https://www.youtube.com/watch?v=fgtkr_4ienw"
              class="btn btn-default"><i class="fa fa-play fa-lg"></i> Promo video (3mins) </a>
              <a href="https://dl.acm.org/doi/10.1145/3292500.3330730#sec-supp"
              class="btn btn-default"><i class="fa fa-video-camera fa-lg"></i> Talk (21mins) </a>
          </p>
            </div>
    </div>
    </div>



          
          <!-- PervasiveHealth 2019 -->

                        <div class="media">
        <div class="media-left media-middle hidden-xs hidden-sm">
          <a href="img/pervhealth19.png">
            <img class="media-object" src="img/pervhealth19.png"  style="max-width:250px;" alt="npj">
          </a>
        </div>
        <div class="media-body">
          <h4 class="media-heading"><strong>Passive mobile sensing and psychological traits for large scale mood prediction</strong></h4>
          <p><i>Dimitris Spathis</i>, Sandra Servia, Katayoun Farrahi, Cecilia Mascolo, Jason Rentfrow <br>

          <em>International Conference on Pervasive Computing Technologies for Healthcare<a href="https://doi.org/10.1145/3329189.3329213"
              > (PervasiveHealth'19)</a></em>, Trento, Italy <br>
          <div class="btn-group-sm">
              <a href="https://doi.org/10.1145/3329189.3329213"
              class="btn btn-default"><i class="fa fa-link fa-lg"></i> DOI </a>
              <a href="papers/PH_Passive_mobile_Spathis_et_al.pdf"
              class="btn btn-default"><i class="fa fa-file-pdf-o fa-lg"></i> PDF</a>
          </p>
            </div>
    </div>
    </div>

          <h3>Pre-PhD (2013-2018)</h3> 
          <!-- KBS 2019 -->

          <p>
            <strong>Interactive dimensionality reduction
using similarity projections</strong><br>
            <i>Dimitris Spathis</i>, Nikolaos Passalis, Anastasios Tefas<br>
            <em><a href="http://doi.org/cxbm"
              >Knowledge-Based Systems</a></em>, 165 <br>
            <div class="btn-group-sm">

              <a href="http://doi.org/cxbm"
              class="btn btn-default"><i class="fa fa-link fa-lg"></i> DOI </a>
              <a href="https://arxiv.org/pdf/1811.05531.pdf"
              class="btn btn-default"><i class="fa fa-file-pdf-o fa-lg"></i> PDF</a>
            </div>

          </p>

          <!-- ECCV 2018 -->
          <p>
            <strong>Fast, Visual and Interactive Semi-supervised Dimensionality Reduction</strong><br>
            <i>Dimitris Spathis</i>, Nikolaos Passalis, Anastasios Tefas<br>
            ECCV Efficient Feature Representation Learning workshop<em><a href="http://doi.org/cz6d"
              > (CEFRL @ ECCV'18)</a></em>, Munich, Germany <br>
            
            <div class="btn-group-sm">
              <a href="http://doi.org/cz6d"
              class="btn btn-default"><i class="fa fa-link fa-lg"></i> DOI </a>
              <a href="papers/ECCV_Fast_visual_Spathis_et_al.pdf"
              class="btn btn-default"><i class="fa fa-file-pdf-o fa-lg"></i> PDF</a>
            </div>

          </p>

          <!-- HIJ 2017 -->

          
          <p>
            <strong>Diagnosing Asthma and Chronic Obstructive Pulmonary Disease with Machine Learning</strong><br>
            <i>Dimitris Spathis</i>, Panayiotis Vlamos<br>
            <em><a href="http://doi.org/cbzh"
              >Health Informatics Journal</a></em>, 25(3)<br>
            
            <div class="btn-group-sm">
               <a href="http://doi.org/cbzh"
              class="btn btn-default"><i class="fa fa-link fa-lg"></i> DOI </a>
              <a href="papers/HIJ_Diagnosing_asthma_Spathis_et_al.pdf"
              class="btn btn-default"><i class="fa fa-file-pdf-o fa-lg"></i> PDF</a>
            </div>

          </p>

          <!-- ACL 2017 -->
          <p>
            <strong>Class-based Prediction Errors to Detect Hate Speech with
Out-of-vocabulary Words</strong><br>
            Joan Serra, Ilias Leontiadis, <i>Dimitris Spathis</i>, Gianluca Stringhini, Jeremy Blackburn, Athena Vakali<br>

            ACL Abusive Language Online workshop<em><a href="http://doi.org/b94p"
              > (ALW @ ACL'17)</a></em>, Vancouver, Canada <br>

            <div class="btn-group-sm"> 
               <a href="http://doi.org/b94p"
              class="btn btn-default"><i class="fa fa-link fa-lg"></i> DOI </a>
              <a href="papers/ACL_Class_based_Serra_et_al.pdf"
              class="btn btn-default"><i class="fa fa-file-pdf-o fa-lg"></i> PDF</a>
            </div>
            

          </p>
          

          <!-- EAAI 2016 -->
          <p>
            <strong>A comparison between semi-supervised and supervised text mining techniques on detecting irony in greek political tweets</strong><br>
            Basilis Charalampakis, <i>Dimitris Spathis</i>, Elias Kouslis, Katia Kermanidis<br>
            <em><a href="http://doi.org/bzxq"
              >Engineering Applications of Artificial Intelligence</a></em>, 51<br>
            
      
            <div class="btn-group-sm">

              <a href="http://doi.org/bzxq"
              class="btn btn-default"><i class="fa fa-link fa-lg"></i> DOI </a>
              <a href="papers/EAAI_Detecting_Irony_Charalambakis_et_al.pdf"
              class="btn btn-default"><i class="fa fa-file-pdf-o fa-lg"></i> PDF</a>
            </div>
          </p>

          
          <!-- EANN 2015 -->
          <p>
            <strong>Detecting Irony on Greek Political Tweets: A Text Mining Approach</strong><br>
            Basilis Charalampakis, <i>Dimitris Spathis</i>, Elias Kouslis, Katia Kermanidis<br>
            <em><a href="http://doi.org/bzxr"
              >International Conference on Engineering Applications of Neural Networks</a></em>, Rhodes, Greece<br>
            
            <div class="btn-group-sm">
              <a href="http://doi.org/bzxr"
              class="btn btn-default"><i class="fa fa-link fa-lg"></i> DOI </a>
              <a href="papers/EANN_Detecting_Irony_Charalambakis_et_al.pdf"
              class="btn btn-default"><i class="fa fa-file-pdf-o fa-lg"></i> PDF</a>
            </div>

          </p>

          
          <!-- ER 2017 -->
          <p>
            <strong>Glocal News: An Attempt to Visualize the Discovery of Localized Top Local News, Globally</strong><br>
            <i>Dimitris Spathis</i>, Theofilos Mouratidis, Spyros Sioutas, Athanasios Tsakalidis<br>
            <em><a href="http://doi.org/bzxs"
              >International Conference on Conceptual Modeling</a></em>, Hong Kong, China<br>

            <div class="btn-group-sm">

               <a href="http://doi.org/bzxs"
              class="btn btn-default"><i class="fa fa-link fa-lg"></i> DOI </a>
              <a href="papers/LNCS_Glocal_News_Spathis_et_al.pdf"
              class="btn btn-default"><i class="fa fa-file-pdf-o fa-lg"></i> PDF</a>
            </div>




          </p>



          <h3>Theses</h3>
          <hr>

          <!-- PhD -->
          <p>
            <strong>Machine learning to model health with multimodal mobile sensor data</strong><br>
            PhD thesis <br>
             
            <em>University of Cambridge</em>, 2021
            <div class="btn-group-sm">

               <a href="https://www.repository.cam.ac.uk/handle/1810/333746"
              class="btn btn-default"><i class="fa fa-link fa-lg"></i> DOI </a>
              <a href="https://www.repository.cam.ac.uk/bitstream/handle/1810/333746/Spathis%20PhD%20thesis.pdf?sequence=3&isAllowed=y"
              class="btn btn-default"><i class="fa fa-file-pdf-o fa-lg"></i> PDF</a>
            </div>
          </p>

          <!-- MSc -->
          <p>
            <strong>Learning to interact with high-dimensional data</strong><br>
            MSc thesis <br>
             
            <em>Aristotle University</em>, 2017
            <div class="btn-group-sm">

              <a href="http://ikee.lib.auth.gr/record/289476?ln=en"
              class="btn btn-default"><i class="fa fa-link fa-lg"></i> DOI </a>
              <a href="http://ikee.lib.auth.gr/record/289476/files/GRI-2017-19250.pdf"
              class="btn btn-default"><i class="fa fa-file-pdf-o fa-lg"></i> PDF</a>
            </div>
          </p>

          <h3>Patents</h3>
          <hr>

          <!-- CroSSL -->
          <p>
            <strong>Apparatus & method for generating feature embeddings</strong><br>
             
            <em>Nokia</em>, US20240273404A1 (filed 2023, published 2024)
            <div class="btn-group-sm">

               <a href="https://patents.google.com/patent/US20240273404A1/"
              class="btn btn-default"><i class="fa fa-link fa-lg"></i> Google Patents </a>
              <a href="https://patentimages.storage.googleapis.com/60/76/aa/b6c06c5141046d/US20240273404A1.pdf"
              class="btn btn-default"><i class="fa fa-file-pdf-o fa-lg"></i> PDF</a>
            </div>
          </p>

          <!-- embeddings -->
          <p>
            <strong>Apparatus, method, and computer program for transfer learning</strong><br>
             
            <em>Nokia</em>, US20240127057A1 (filed 2022, published 2024)
            <div class="btn-group-sm">

               <a href="https://patents.google.com/patent/US20240127057A1/en"
              class="btn btn-default"><i class="fa fa-link fa-lg"></i> Google Patents </a>
              <a href="https://patentimages.storage.googleapis.com/84/38/66/c527d2472d0edb/US20240127057A1.pdf"
              class="btn btn-default"><i class="fa fa-file-pdf-o fa-lg"></i> PDF</a>
            </div>
          </p>

          
          
        </div>


        <div class="row">
          <h2><a name="service"></a>🧐 Academic service</h2>
          <hr>
          
        
          <p>
              <strong>Leadership & Organizer roles</strong>:

            <ul>

              <li>
                Organizer of <a href="https://faircomp-workshop.github.io/2024//">FairComp</a> & <a href="https://wellcomp2024.github.io//">WellComp</a> workshops at UbiComp 2024, Melbourne, Australia.
               </li>

              <li>
                General co-chair of <a href="https://hcrl-workshop.github.io/2024/">HCRL</a> workshop at AAAI 2024, Vancouver, Canada.
               </li>

               <li>
                Editorial board member of <a href="https://www.nature.com/npjdigitalmed/">Nature Digital Medicine</a> (2023-).
               </li>

               <li>
                Editorial board member of <a href="https://www.computer.org/csdl/magazine/pc/about/15004/">IEEE Pervasive Computing</a> (2023-).
               </li>

              <li>
               General co-chair of <a href="https://faircomp-workshop.github.io/2023/">FairComp</a> & <a href="https://wellcomp-workshop.github.io/2023/">WellComp</a> workshops at UbiComp 2023, Cancun, Mexico.
              </li>

              <li>
                Session chair on Industry Perspectives at <a href="https://mobilehci.acm.org/2023/program.php">MobileHCI 2023</a>, Athens, Greece.
               </li>

              <li>
               Co-organizer and track chair of <a href="https://www.chilconference.org/">CHIL 2023</a>, Boston, USA.
              </li>

            	<li>

               Senior panel/roundtable chair at <a href="https://ml4health.github.io/2022//">ML4H 2022</a>, New Orleans, USA.
           		</li>

              <li>
               Chair of <a href="https://wellcomp-workshop.github.io/2022/">WellComp</a> workshop at UbiComp 2022, Cambridge, UK.
              </li>

              <li>

              Session chair on data science for rich data types at <a href="https://kdd.org/kdd2021">KDD 2021</a>, Singapore/online.
                </li>

            	<li>

               Co-organizer of the <a href="https://federatedsensing.gitlab.io/">Federated sensing tutorial</a> at <span title="Annual International Conference On Mobile Computing And Networking" data-toggle="tooltip" data-placement="bottom" >MobiCom 2021</span>, New Orleans, USA.
           		</li>

           		

           		
   			</ul>
                
          </p>

          <p>
              <strong>Program Committee Member</strong>: 
              <span title="AAAI Conference on Artificial Intelligence" data-toggle="tooltip" data-placement="bottom" ><a href="https://aaai.org/Conferences/AAAI-21/wp-content/uploads/2021/05/AAAI-21-Program-Committee.pdf">AAAI</a> 2021-2024</span>,

              <span title="International Joint Conference on Artificial Intelligence" data-toggle="tooltip" data-placement="bottom" ><a href="https://www.ijcai.org/proceedings/2020/preface.pdf">IJCAI</a> 2020</span>,

              <span title="ACM International Conference on Knowledge Discovery & Data Mining" data-toggle="tooltip" data-placement="bottom" ><a href="https://kdd.org/kdd2021/organizers/PC_SPC">KDD</a> 2020-2023</span>,

              <span title="ACM Conference on Fairness, Accountability, and Transparency (ACM FAccT)" data-toggle="tooltip" data-placement="bottom" ><a href="https://facctconference.org/2023/committees.html">FAccT</a> 2023</span>,

               <span title="SIAM International Conference on Data Mining" data-toggle="tooltip" data-placement="bottom" >SIAM SDM 2022</span>, 

               <a href="https://www.sensiblend.io/organizers/">Sensiblend</a> @ <span title="ACM Proceedings on Interactive, Mobile, Wearable and Ubiquitous Technologies" data-toggle="tooltip" data-placement="bottom">Ubicomp 2021</span>, 

               <a href="https://mobiquitous.eai-conferences.org/2022/technical-program-committee/">Mobiquitous</a> 2022.

                
        	</p>


        	<p>
              <strong>Reviewer</strong>: <span title="Conference on Neural Information Processing Systems" data-toggle="tooltip" data-placement="bottom" >NeurIPS</span>,
              <span title="International Conference on Learning Representations" data-toggle="tooltip" data-placement="bottom" >ICLR</span>, 

              <span title="International Conference on Machine Learning" data-toggle="tooltip" data-placement="bottom" >ICML</span>, 

              <span title="AAAI Conference on Artificial Intelligence" data-toggle="tooltip" data-placement="bottom" >AAAI</span>, 

	          <span title="International Joint Conference on Artificial Intelligence" data-toggle="tooltip" data-placement="bottom" >IJCAI</span>, 

	          <span title="ACM International Conference on Knowledge Discovery & Data Mining" data-toggle="tooltip" data-placement="bottom" >KDD</span>,

	          <span title="ACM Conference on Human Factors in Computing Systems" data-toggle="tooltip" data-placement="bottom" >CHI</span>, 

	          <span title="ACM Proceedings on Interactive, Mobile, Wearable and Ubiquitous Technologies" data-toggle="tooltip" data-placement="bottom" >Ubicomp/IMWUT</span>, 

            <span title="Conference on Health, Inference, and Learning" data-toggle="tooltip" data-placement="bottom" >CHIL</span>, Nature Digital Medicine, WACV, Nature Scientific Reports,

	          <span title="IEEE International Conference on Acoustics, Speech and Signal Processing" data-toggle="tooltip" data-placement="bottom" >ICASSP</span>, 

              Expert Systems with Applications, Neurocomputing,
              WWW/The Web Conference, Engineering Applications of Artificial Intelligence, 

              <span title="AAAI International Conference on Web and Social Media" data-toggle="tooltip" data-placement="bottom" >ICWSM</span>,

               and more.
        	</p>
          
        </div>

          <div class="row">
          <h2><a name="talks"></a>📢 Invited talks</h2>
          <hr>

          <em>Evidence from industry – what are you really using AI for? (panel)</em>
          <ul style="list-style-type: lower-alpha; list-style: none;">
             <li style="margin-left:0.1em">📍 <a href="https://cambridgetechweek.co.uk/events/tech-deep-dive-ai-quantum/"> Cambridge Tech Week</a>, Cambridge, UK<span style="font-size:13px; vertical-align:center"> — September 11, 2024</span></li>
         </ul>

          <em>Multimodal AI for Real-World Signals and the Role of Language</em>
          <ul style="list-style-type: lower-alpha; list-style: none;">
             <li style="margin-left:0.1em">📍 <a href="https://w3phiai2024.w3phi.com/keynote-speakers.html"> AAAI'24 Health Intelligence workshop</a>, Vancouver, Canada<span style="font-size:13px; vertical-align:center"> — February 27, 2024</span></li>
         </ul>

          <em>Multimodal, data-efficient, and robust AI for real-world biosignals & the role of generative models        </em>
          <ul style="list-style-type: lower-alpha; list-style: none;">
             <li style="margin-left:0.1em">📍 <a href="https://talks.cam.ac.uk/talk/index/210049"> Cambridge MedAI Seminar Series</a>, Biomedical Campus, Cambridge, UK<span style="font-size:13px; vertical-align:center"> — January 30, 2024</span></li>
         </ul>

          <em>Multimodal AI for real-world signals – does the key to specialized models lie in language?          </em>
          <ul style="list-style-type: lower-alpha; list-style: none;">
             <li style="margin-left:0.1em">📍 <a href="https://www.ellis.eng.cam.ac.uk/microsoft-ai-pizza-talk-30-november-2023/"> Microsoft AI & Pizza talk -
   </a> Cambridge ELLIS Unit, Cambridge, UK<span style="font-size:13px; vertical-align:center"> — November 30, 2023</span></li>
         </ul>

          <em>Human-centric AI for health signals with applications in fitness and activity modeling </em>
       <ul style="list-style-type: lower-alpha; list-style: none;">
          <li style="margin-left:0.1em">📍 <a href="https://www.cph.cam.ac.uk/events/using-mobiles-and-wearables-public-health"> Cambridge Public Health symposium,
</a> Cambridge, UK<span style="font-size:13px; vertical-align:center"> — March 27, 2023</span></li>
      </ul>

          <em>Self-Supervised Learning for Health Signals </em>
       <ul style="list-style-type: lower-alpha; list-style: none;">
          <li style="margin-left:0.1em">📍 <a href="https://cemse.kaust.edu.sa/ai/aii-symp-2023"> Rising Stars in AI</a>, KAUST, Saudi Arabia<span style="font-size:13px; vertical-align:center"> — February 20, 2023</span></li>
      </ul>

          <em>Representation learning for cardio-fitness prediction in free-living environments </em>
       <ul style="list-style-type: lower-alpha; list-style: none;">
          <li style="margin-left:0.1em">📍 <a href="https://www.kcl.ac.uk/mental-health-and-psychological-sciences/about/departments/biostatistics-and-health-informatics?"> King's College London</a>, Precision Health Informatics Data Lab, London, UK<span style="font-size:13px; vertical-align:center"> — November 24, 2022</span></li>
      </ul>

          <em>AI-powered Wearables Transforming Mobile Health </em>
       <ul style="list-style-type: lower-alpha; list-style: none;">
          <li style="margin-left:0.1em">📍 <a href="https://web.archive.org/web/20230207171247/https://london.theaisummit.com/speakers/dimitris-spathis"> AI Summit</a>, London Tech week, London, UK<span style="font-size:13px; vertical-align:center"> — June 16, 2022</span></li>
      </ul>

          <em>Self-supervised learning for health signals</em>
       <ul style="list-style-type: lower-alpha; list-style: none;">
          <li style="margin-left:0.1em">📍 <a href="https://feinstein.northwell.edu/"> Feinstein Institutes of Northwell Health</a>, New York, USA (remote)<span style="font-size:13px; vertical-align:center"> — March 22, 2022</span></li>
      </ul>
          
			 <em>AI to model Human Behaviour and Health</em>
			 <ul style="list-style-type: lower-alpha; list-style: none;">
        <li style="margin-left:0.1em">📍 <a href="https://mcr.jesus.cam.ac.uk/conference/">Jesus College Postgraduate Conference</a>, virtual event, UK <span style="font-size:13px; vertical-align:center">— March 5, 2021</span></li>   
				  <li style="margin-left:0.1em">📍 <a href="https://labs.uk.barclays/">Barclays</a> Eagle Lab, Cambridge, UK <span style="font-size:13px; vertical-align:center">— March 12, 2020</span></li>
          
 			</ul>


			<em>Deep sequence learning for large-scale inference of human behaviour from mobile sensor data</em>
			 <ul style="list-style-type: lower-alpha; list-style: none;">
				  <li style="margin-left:0.1em">📍  <a href="https://www.mrc-epid.cam.ac.uk/">MRC Epidemiology Unit</a>, University of Cambridge, UK<span style="font-size:13px; vertical-align:center"> — March 5, 2019</span></li>
				  <li style="margin-left:0.1em">📍 <a href="https://www.ocadogroup.com/technology/technology-pioneers">Ocado</a>, Barcelona, Spain & Hatfield, UK (remote) <span style="font-size:13px; vertical-align:center"> — July 10, 2019</span></li>
			</ul>

			<em>Fast, Visual and Interactive Semi-supervised Dimensionality Reduction</em>
			 <ul style="list-style-type: lower-alpha; list-style: none;">
				  <li style="margin-left:0.1em">📍 <a href="https://ai.facebook.com/">Facebook</a> PhD Open House, London, UK <span style="font-size:13px; vertical-align:center"> — October 25, 2018</span></li>
			</ul>

        </div>

        <div class="row">
          <h2><a name="press"></a>🗞️ Press</h2>
          <hr>
          <p>Large Language Models for timeseries: 

            <a href="https://techcrunch.com/2024/07/06/tokens-are-a-big-reason-todays-generative-ai-falls-short/">Techcrunch</a>, <a href="https://www.lgresearch.ai/blog/view?seq=428">LG AI Research</a>. 
           </p>

          <p>
            Audio AI for COVID-19: 
              <a href="https://www.cam.ac.uk/research/news/new-app-collects-the-sounds-of-covid-19">Cambridge University (1)</a>,
              <a href="https://www.cst.cam.ac.uk/news/your-phone-could-tell-us-if-you-have-coronavirus">(2)</a>,
              <a href="https://www.cst.cam.ac.uk/news/presenting-hall-fame-awards">(3)</a>,
              <a href="https://www.cst.cam.ac.uk/news/remote-monitoring-successfully-tracks-covid-19-progression-over-time">(4)</a>,
              <a href="https://www.bbc.co.uk/news/technology-52215290">BBC</a>,
              <a href="https://www.theguardian.com/world/2020/sep/21/what-is-persistent-cough-and-how-to-i-recognise-it-coronavirus-covid">The Guardian</a>,
              <a href="https://www.ft.com/content/af763300-9fc6-4863-b5bf-c3e670301c09">Financial Times</a>,
              <a href="https://archive.ph/IRAX1">The Times</a>,
              <a href="https://www.forbes.com/sites/marcwebertobias/2020/05/05/ai-and-medical-diagnostics-can-a-smartphone-app-detect-covid-19-from-speech-or-a-cough/#144df95f5436">Forbes</a>,
              <a href="https://slate.com/technology/2020/04/cough-covid19-coronavirus-app.html">Slate</a>,
              <a href="https://www.huffingtonpost.co.uk/entry/resapp-phone-cough-covid-test_uk_625e7b1fe4b0be72bffa32e9">Huffington Post</a>,
              <a href="https://www.dailymail.co.uk/sciencetech/article-8192043/Cough-Researchers-launch-Covid-19-Sounds-App.html">DailyMail</a>,
              <a href="https://www.itv.com/news/anglia/2020-04-06/scientists-want-cough-recordings-to-help-diagnose-covid-19/">ITV</a>,
              <a href="https://spectrum.ieee.org/ai-recognizes-covid-19-in-the-sound-of-a-cough">IEEE Spectrum</a>,
              <a href="https://thenextweb.com/news/researchers-want-your-voice-to-train-coronavirus-detecting-ai">TheNextWeb</a>,
              <a href="https://us11.campaign-archive.com/?u=f8609630ae206654824f897b6&id=d274162ebb">STAT</a>,
              <a href="https://www.epfl.ch/labs/esl/the-race-between-researchers-for-the-diagnosis-of-covid-19-in-the-sound-of-a-cough/">EPFL</a>,
              <a href="https://www.the-scientist.com/news-opinion/ai-assisted-cough-tracking-could-help-detect-the-next-pandemic--68233">TheScientist</a>,
              <a href="https://www.theregister.com/2020/04/06/covid19_app_collects_sound_of_your_cough/">The Register</a>,
              <a href="https://www.kdnuggets.com/2020/12/covid-cough-ai-detecting-sounds.html">KDnuggets</a>,
              <a href="https://www.wbur.org/hereandnow/2020/12/03/detecting-covid-19-through-sound">NPR/WBUR</a>,
              <a href="https://www.psychologytoday.com/gb/blog/language-in-the-wild/202012/is-voice-test-covid-coming-smartphone-near-you">Psychology Today</a>,
              <a href="https://elpais.com/tecnologia/2020-04-25/se-buscan-donantes-de-voz-para-capturar-los-sonidos-de-la-covid-19.html">El Pais</a>,
              <a href="http://www.rainews.it/dl/rainews/media/130420-323-varvello-uk-virus-463ba7c4-b4fd-4ae1-a6e4-9ca5a20767d2.html">RAI</a>,
              <a href="https://www.corriere.it/salute/ehealth/cards/aiutateci-realizzare-web-app-monitorare-casa-segnali-coronavirus/studio-cambridge.shtml">Corriere della Sera</a>,
              <a href="https://www.focus.it/scienza/salute/un-app-capisce-dalla-voce-se-abbiamo-la-covid">Focus</a>,
              <a href="https://www.derstandard.at/jetzt/livebericht/2000116635062/1000186508/fast-2-000-tote-in-den-usa-binnen-eines-tages">DerStandard</a>.
             </p>


             <p> AI for wearables:
              <a href="https://www.cam.ac.uk/research/news/fitness-levels-can-be-accurately-predicted-using-wearable-devices-no-exercise-required">Cambridge University (1)</a>,
              <a href="https://www.cam.ac.uk/business/nokiabelllabs">(2)</a>,
              <a href="https://archive.ph/ZRPsa">New York Times</a>,
              <a href="https://www.bloomberg.com/news/newsletters/2024-10-11/what-is-vo2-max">Bloomberg</a>,
              <a href="https://venturebeat.com/2020/11/11/researchers-claim-ai-algorithm-use-heart-rate-and-motion-data-to-predict-age-sex-and-more/">VentureBeat</a>,
              <a href="https://archive.ph/JkOp6">Business Insider</a>,
              <a href="https://www.runnersworld.com/training/a61402979/how-to-calculate-vo2-max/">Runner's World</a>,
              <a href="https://cacmb4.acm.org/careers/267362-wearable-devices-accurately-predict-fitness-levels/fulltext">Communications of the ACM</a>,
              <a href="https://www.mirror.co.uk/news/health/put-your-fitness-test-latest-29176920">Daily Mirror</a>,
              <a href="https://www.bicycling.com/health-nutrition/a42406388/fitness-tracker-hack-your-health/">Bicycling Magazine</a>, 
              <a href="https://www.owkin.com/newsfeed/surfing-the-healthcare-wave-at-icml">Owkin</a>,
              <a href="https://scilogs.spektrum.de/hlf/ubiquitous-computing-an-hlf-laureate-pioneering-a-field-that-shows-up-everywhere/">Spektrum.de</a>.



             </p>

             <p> Data-driven music psychology:
              <a href="https://www.cam.ac.uk/stories/musical-preferences-unite-personalities-worldwide">Cambridge University</a>,
              <a href="https://archive.ph/HtQvL#selection-735.0-735.85">The Times</a>,
              <a href="https://www.washingtonpost.com/science/2022/09/25/music-taste-personality-traits/">Washington Post</a>,
              <a href="https://edition.cnn.com/2022/04/07/health/music-brain-wellness-scn/index.html">CNN</a>,
              <a href="https://www.telegraph.co.uk/news/2022/02/09/fans-ed-sheeran-extroverts-says-cambridge-study-music-personality/">The Telegraph</a>,
              <a href="https://news.sky.com/story/what-does-your-music-taste-say-about-your-personality-study-uncovers-link-between-listening-tastes-and-character-traits-12538105">Sky News</a>,
              <a href="https://www.itv.com/news/anglia/2022-02-10/what-your-music-tastes-say-about-you-why-fans-of-ed-sheeran-are-extroverts">ITV</a>,
              <a href="https://www.dailymail.co.uk/sciencetech/article-10494393/What-music-choice-says-personality.html">DailyMail</a>,
              <a href="https://www.inc.com/jessica-stillman/hiring-music-taste-study.html">Inc.</a>,
              <a href="https://www.ctvnews.ca/lifestyle/personality-and-musical-preference-are-connected-largely-the-same-way-no-matter-where-you-live-study-1.5779935">CTV</a>,
              <a href="https://www.facebook.com/ZDFterraX/videos/632525978041682/?__tn__=%2CO">ZDF</a>,
              <a href="https://archive.ph/eABli">Der Tagesspiegel</a>,
              <a href="https://archive.ph/ZtxHS">ABC.ES</a>,
              <a href="https://www.abc.net.au/radio/programs/aca-on-demand/what-does-your-music-choice-say-about-your/13753990">ABC.AU</a>,
              <a href="https://www.elle.fr/Love-Sexe/News/Nos-gouts-musicaux-varient-en-fonction-de-notre-personnalite-3994308">ELLE</a>,
              <a href="https://www.cosmopolitan.fr/ce-que-vos-gouts-musicaux-revelent-de-votre-personnalite,2055654.asp">Cosmopolitan</a>,
              <a href="https://www.rtbf.be/article/notre-playlist-musicale-le-reflet-de-notre-personnalite-10934854">RTBF</a>,
              <a href="https://youtu.be/evVRxrOo5iw">TEDx</a>.
             </p>

             <p>Interviews: <a href="https://indiaai.gov.in/article/there-is-huge-potential-for-clinical-ai-in-the-future-dimitris-spathis-nokia-bell-labs">IndiaAI.gov</a>
             </p>


             
          

        </div>



        <div class="row">
          <h2><a name="teaching"></a>🎒 Mentoring</h2>
          <hr>
          <p>
          I enjoy collaborating with PhD and thesis students, usually as part of an internship in our lab. Here are some recent research projects I supervised:
          </p>   

          <ul>
          	<li>Chi Ian Tang (University of Cambridge): Self-supervised and continual learning </li>
             <li>Benjamin Searle (University of Cambridge): Capturing compulsive behaviours w/ wearables </li>
             <li>Kevalee Shah (University of Cambridge): Benchmarking contrastive learning algorithms </li>
             <li>Chuen Low (University of Cambridge): Attention models for timeseries </li>
             <li>Yu Yvonne Wu (University of Cambridge): Weakly-supervised and self-supervised learning </li>
             <li>Shohreh Deldari (UNSW Sydney): Multimodal self-supervised learning </li>
             <li>Sofia Yfantidou (Aristotle University): Machine learning fairness </li>
             <li>Francesco Pase (University of Padova): Self-supervised federated learning </li>
             <li>Aashish Kolluri  (National University of Singapore): Multimodal adapters for large models </li>
             <li>Ryuhaerang Choi (KAIST): Data-centric multi-task learning </li>
             <li>Arvind Pillai (Dartmouth College): Foundation models for physiological signals </li>

             
              
          </ul>



          <p>
            I have also been a teaching assistant for the following undergraduate courses:
            </p>   

          <ul>
             <li><a href="https://www.cl.cam.ac.uk/teaching/1819/MLRD/">Machine Learning & Real-World Data</a> (U. of Cambridge)</li>
             <li><a href="https://www.cl.cam.ac.uk/teaching/1819/MobSensSys/">Mobile & Sensor Systems</a> (U. of Cambridge)</li>
             <li><a href="https://www.cl.cam.ac.uk/teaching/1819/SciComp/">Scientific Computing</a> (U. of Cambridge)</li>
             <li><a href="https://qa.auth.gr/en/class/1/600121197/M1">Numerical Analysis</a> (Aristotle University)</li>
          </ul>
        </div>

        <div class="row">
          <h2><a name="projects"></a>🎠 Playground</h2>
          <hr>

          <blockquote class="blockquote text-right" style="border-left:none">
          <p class="mb-0">“The next big thing in technology often starts off looking like a toy”</p>
          <footer class="blockquote-footer">Chris Dixon (<a href="https://cdixon.org/2010/01/03/the-next-big-thing-will-start-out-looking-like-a-toy">2010</a>)</footer>
        </blockquote>


          
            <h4>Quantifying name-dropping</h4>
            <a href="http://communitypoprefs.com">
              <img src="img/community.jpg" style="max-width:100%;" />
            </a>
            <p>
            <a href="http://communitypoprefs.com/">Communitypoprefs.com</a> is a data visualization website, where we present every pop-culture reference over the course of 5 seasons of the TV series <em>Community</em>.
            </p>
            <br>

          
            <h4>Map out your music taste on Spotify</h4>
            <a href="https://medium.com/p/fe50c94b8af3">
              <img src="img/spotify.png" style="max-width:100%;" />
            </a>
            <p>
            Visualizing my favourite songs on Spotify with dimensionality reduction and anomaly detection. <a href="https://medium.com/p/fe50c94b8af3/">Data essay</a> published in <em>Cuepoint Magazine</em>, Medium's premier music publication.
            </p>
            <br>


            <h4>Children books and childish language?</h4>
            <a href="http://medium.com/p/100290c94242">
              <img src="img/books.png" style="max-width:100%;" />
            </a>
            <p>
            Text mining Game of Thrones, Harry Potter, Hunger Games and Lord of the Rings books. <a href="http://medium.com/p/100290c94242/" >Data essay </a>featured in Medium's Editor Picks.
            </p>
            <br>

            <h4>Anonymize kids' faces before posting online</h4>
            <a href="https://devpost.com/software/patronus-k61iv4">
              <img src="img/patronous.png" style="max-width:100%;" />
            </a>
            <p>
            <a href="https://devpost.com/software/patronus-k61iv4/">Mobile app</a> with face recognition, age estimation, & emotion recognition to blur
kids or replace their face with emotion-based emoji. Developed during <em>HackZurich 2018</em>.
            </p>
            <br>

            <h4>Discover top local news globally</h4>
            <a href="https://github.com/sdimi/glocalnews.js">
              <img src="img/glocal.jpg" style="max-width:100%;" />
            </a>
            <p>
            <a href="https://github.com/sdimi/glocalnews.js/">Glocalne.ws</a> was a mashup of Google News and Google Maps. Unfortunately it is now defunct due to API discontinuance.
            </p>
            <br>


            <h4>Composing music and text with Recurrent Neural Networks</h4>
            <a href="https://web.archive.org/web/20160628133340/http://users.auth.gr/sdimitris/rnn">
              <img src="img/rnn.png" style="max-width:100%;" />
            </a>
            <p>Training neural networks on massive amounts of musical notation and literature and letting them create their own art. <a href="https://web.archive.org/web/20160628133340/http://users.auth.gr/sdimitris/rnn">Essay</a> in Greek but you can still see/listen to the results.
            </p>
            
          




          
          
        </div>

        <div class="row">
          <h2><a name="personal"></a>🕳️🐇 Personal</h2>
          <hr>
            <p>
            Non-academic things about me: I love music, both playing and listening. I am mostly into art rock and indie folk, with the occasional exception of some well-crafted pop. Although I am an accordionist by training, over the last few years I've been playing mostly piano and ukulele. In a previous life, I performed with the critically acclaimed band <i>The Children of the Oldness</i> (aka <a href="https://en.wikipedia.org/wiki/Kore._Ydro.">Kore Ydro</a>) and recorded the album <i>"Consortium in Amato"</i> (<a href="https://paidiatispalaiotitas.bandcamp.com/album/consortium-in-amato">listen here</a>). </p>

            <p>I also enjoy street photography and in particular playing with light—photography comes from Greek φως (light) and γραφή (writing), or <em>drawing with light</em>. A sample of my shots is on <a href="https://flickr.com/sdimitris">Flickr</a> and one of my landscapes was featured in the <a href="http://huff.to/17N58jI">Huffington Post</a>.</p>

            <p>Lastly, and perhaps most importantly, I'm always on the lookout for ways to move items from the "non-academic list" to the "academic list"—let me know if you'd like to help!
            </p>     
          
        </div>
      </div>
    </div>
    <footer>
    &nbsp;
    </footer>
  </div>

  <!-- JavaScript -->
  <script src="https://code.jquery.com/jquery-3.1.1.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
  <!-- display tooltips for social links -->
  <script>
$(function () {
  $('[data-toggle="tooltip"]').tooltip() 
})
</script>
  
</body>
</html>
